import os
import re
import shutil
from pathlib import Path
import logging
from colorama import init, Fore, Style
from tqdm import tqdm
import zipfile
import py7zr
import rarfile
import patoolib

# åˆå§‹åŒ– colorama
init()

# é…ç½®æ—¥å¿—
class ColoredFormatter(logging.Formatter):
    def format(self, record):
        if "ç§»åŠ¨" in record.msg:
            record.msg = f"ğŸ”„ {Fore.YELLOW}{record.msg}{Style.RESET_ALL}"
        elif "é”™è¯¯" in record.msg:
            record.msg = f"âŒ {Fore.RED}{record.msg}{Style.RESET_ALL}"
        elif "ä¿ç•™" in record.msg:
            record.msg = f"âœ… {Fore.GREEN}{record.msg}{Style.RESET_ALL}"
        elif "æ£€æŸ¥ç›®å½•" in record.msg:
            record.msg = f"ğŸ“‚ {Fore.BLUE}{record.msg}{Style.RESET_ALL}"
        else:
            record.msg = f"â„¹ï¸ {Fore.WHITE}{record.msg}{Style.RESET_ALL}"
        return super().format(record)

# é…ç½®æ—¥å¿—å¤„ç†å™¨
logging.basicConfig(level=logging.INFO)
console_handler = logging.StreamHandler()
console_handler.setFormatter(ColoredFormatter('%(message)s'))
logging.getLogger('').handlers = [console_handler]

def normalize_filename(filename):
    """æ ‡å‡†åŒ–æ–‡ä»¶åï¼ˆå»é™¤æ•°å­—åç¼€å’Œç©ºæ ¼ï¼‰"""
    # å»é™¤æ‰©å±•å
    base, ext = os.path.splitext(filename)
    
    # å»é™¤æ•°å­—åç¼€
    base = re.sub(r'_\d', '', base)
    
    # å»é™¤æ‰€æœ‰ç©ºæ ¼
    base = re.sub(r'\s+', '', base)
    
    return base.lower() + ext.lower()

def count_images_in_archive(archive_path):
    """ç»Ÿè®¡å‹ç¼©åŒ…ä¸­çš„å›¾ç‰‡æ–‡ä»¶æ•°é‡"""
    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.jxl', '.avif'}
    count = 0
    
    try:
        if archive_path.lower().endswith('.zip'):
            with zipfile.ZipFile(archive_path, 'r') as zip_ref:
                for name in zip_ref.namelist():
                    if any(name.lower().endswith(ext) for ext in image_extensions):
                        count += 1
        elif archive_path.lower().endswith('.7z'):
            with py7zr.SevenZipFile(archive_path, 'r') as sz_ref:
                for name in sz_ref.getnames():
                    if any(name.lower().endswith(ext) for ext in image_extensions):
                        count += 1
        elif archive_path.lower().endswith('.rar'):
            with rarfile.RarFile(archive_path, 'r') as rar_ref:
                for name in rar_ref.namelist():
                    if any(name.lower().endswith(ext) for ext in image_extensions):
                        count += 1
        return count
    except Exception as e:
        logging.error(f"è¯»å–å‹ç¼©åŒ… {os.path.basename(archive_path)} æ—¶å‡ºé”™: {str(e)}")
        return -1

def get_directory_depth(path, base_path):
    """è·å–ç›®å½•ç›¸å¯¹äºåŸºç¡€è·¯å¾„çš„æ·±åº¦"""
    rel_path = os.path.relpath(path, base_path)
    return len(Path(rel_path).parts)

def process_directory(dir_path, source_dir, trash_dir):
    """å¤„ç†å•ä¸ªç›®å½•ä¸­çš„é‡å¤æ–‡ä»¶"""
    # ç”¨äºå­˜å‚¨å½“å‰ç›®å½•ä¸‹çš„æ–‡ä»¶
    file_groups = {}
    total_files = 0
    moved_count = 0
    duplicate_groups = 0
    
    # è·å–å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆåŒ…æ‹¬å­ç›®å½•ä¸­çš„æ–‡ä»¶ï¼‰
    all_files = []
    for root, _, files in os.walk(dir_path):
        # å¦‚æœæ˜¯å½“å‰ç›®å½•ä¸‹çš„æ–‡ä»¶ï¼Œç›´æ¥æ·»åŠ 
        if root == dir_path:
            all_files.extend((root, f) for f in files)
    
    # æ”¶é›†å‹ç¼©æ–‡ä»¶
    for root, file in all_files:
        if file.lower().endswith(('.zip', '.rar', '.7z')):
            total_files += 1
            normalized_name = normalize_filename(file)
            full_path = os.path.join(root, file)
            
            if normalized_name not in file_groups:
                file_groups[normalized_name] = []
            file_groups[normalized_name].append(full_path)
    
    # å¤„ç†é‡å¤æ–‡ä»¶
    if total_files > 0:
        rel_path = os.path.relpath(dir_path, source_dir)
        logging.info(f"\næ£€æŸ¥ç›®å½•: {rel_path} ({total_files} ä¸ªå‹ç¼©æ–‡ä»¶)")
        
        for base_name, files in file_groups.items():
            if len(files) > 1:
                duplicate_groups += 1
                # è·å–æ¯ä¸ªæ–‡ä»¶çš„å›¾ç‰‡æ•°é‡
                file_info = []
                
                # æ‰“å°é‡å¤æ–‡ä»¶ç»„ä¿¡æ¯
                logging.info(f"\nå‘ç°é‡å¤æ–‡ä»¶ç»„:")
                for file_path in files:
                    image_count = count_images_in_archive(file_path)
                    is_original = not bool(re.search(r"_\d+\.", os.path.basename(file_path)))
                    file_info.append((file_path, image_count, is_original))
                    logging.info(f"  - {os.path.basename(file_path)} (å›¾ç‰‡æ•°: {image_count}, {'åŸå§‹æ–‡ä»¶' if is_original else 'éåŸå§‹æ–‡ä»¶'})")
                
                # æŒ‰å›¾ç‰‡æ•°é‡æ’åº
                file_info.sort(key=lambda x: (-x[1], x[2]))  # æŒ‰å›¾ç‰‡æ•°é‡é™åºï¼ŒåŸå§‹æ–‡ä»¶ä¼˜å…ˆ
                
                # æ‰¾å‡ºè¦ä¿ç•™çš„æ–‡ä»¶
                files_to_keep = []
                max_count = file_info[0][1]  # æœ€å¤§å›¾ç‰‡æ•°é‡
                
                # æ‰¾å‡ºåŸå§‹æ–‡ä»¶å’Œå›¾ç‰‡æ•°é‡æœ€å¤šçš„æ–‡ä»¶
                original_file = next((f for f in file_info if f[2]), None)  # æ‰¾åŸå§‹æ–‡ä»¶
                max_count_file = file_info[0]  # å›¾ç‰‡æœ€å¤šçš„æ–‡ä»¶
                
                if original_file:
                    if original_file[1] >= max_count:  # å¦‚æœåŸå§‹æ–‡ä»¶å›¾ç‰‡æ•°é‡æœ€å¤šæˆ–ç›¸ç­‰
                        files_to_keep = [original_file]
                        logging.info(f"\nä¿ç•™åŸå§‹æ–‡ä»¶ (å›¾ç‰‡æ•°æœ€å¤š): {os.path.basename(original_file[0])} (å›¾ç‰‡æ•°: {original_file[1]})")
                    else:  # å¦‚æœåŸå§‹æ–‡ä»¶å›¾ç‰‡æ•°é‡ä¸æ˜¯æœ€å¤š
                        files_to_keep = [original_file, max_count_file]
                        logging.info(f"\nåŒæ—¶ä¿ç•™:")
                        logging.info(f"  - åŸå§‹æ–‡ä»¶: {os.path.basename(original_file[0])} (å›¾ç‰‡æ•°: {original_file[1]})")
                        logging.info(f"  - å›¾ç‰‡æœ€å¤šçš„æ–‡ä»¶: {os.path.basename(max_count_file[0])} (å›¾ç‰‡æ•°: {max_count_file[1]})")
                else:  # å¦‚æœæ²¡æœ‰åŸå§‹æ–‡ä»¶ï¼Œä¿ç•™å›¾ç‰‡æœ€å¤šçš„
                    files_to_keep = [max_count_file]
                    logging.info(f"\nä¿ç•™å›¾ç‰‡æœ€å¤šçš„æ–‡ä»¶: {os.path.basename(max_count_file[0])} (å›¾ç‰‡æ•°: {max_count_file[1]})")
                
                # ç§»åŠ¨å…¶ä»–æ–‡ä»¶
                for file_path, img_count, is_original in file_info:
                    if not any(file_path == keep_file[0] for keep_file in files_to_keep):
                        try:
                            # æ„å»ºç›®æ ‡è·¯å¾„ï¼Œä¿æŒåŸæœ‰çš„ç›®å½•ç»“æ„
                            rel_path = os.path.relpath(os.path.dirname(file_path), source_dir)
                            target_dir = os.path.join(trash_dir, rel_path)
                            Path(target_dir).mkdir(parents=True, exist_ok=True)
                            
                            target_path = os.path.join(target_dir, os.path.basename(file_path))
                            
                            # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ•°å­—åç¼€
                            if os.path.exists(target_path):
                                base, ext = os.path.splitext(target_path)
                                counter = 1
                                while os.path.exists(f"{base}_{counter}{ext}"):
                                    counter += 1
                                target_path = f"{base}_{counter}{ext}"
                            
                            # ç§»åŠ¨æ–‡ä»¶
                            shutil.move(file_path, target_path)
                            moved_count += 1
                            rel_source_path = os.path.relpath(file_path, source_dir)
                            rel_target_path = os.path.relpath(target_path, trash_dir)
                            logging.info(f"ç§»åŠ¨: {rel_source_path} -> {rel_target_path} (å›¾ç‰‡æ•°: {img_count})")
                            
                        except Exception as e:
                            logging.error(f"ç§»åŠ¨æ–‡ä»¶æ—¶å‡ºé”™ {os.path.relpath(file_path, source_dir)}: {str(e)}")
    
    return total_files, duplicate_groups, moved_count

def process_duplicates(source_dir, trash_dir):
    """å¤„ç†æ‰€æœ‰ç›®å½•ä¸‹çš„é‡å¤æ–‡ä»¶ï¼Œä»æœ€æ·±å±‚å¼€å§‹"""
    # ç¡®ä¿trashç›®å½•å­˜åœ¨
    Path(trash_dir).mkdir(parents=True, exist_ok=True)
    
    # æ”¶é›†æ‰€æœ‰ç›®å½•åŠå…¶æ·±åº¦
    all_dirs = []
    for root, dirs, _ in os.walk(source_dir):
        # è·³è¿‡trashç›®å½•
        if os.path.abspath(root) == os.path.abspath(trash_dir):
            continue
        all_dirs.append((root, get_directory_depth(root, source_dir)))
    
    # æŒ‰æ·±åº¦é™åºæ’åºç›®å½•ï¼ˆæœ€æ·±çš„å…ˆå¤„ç†ï¼‰
    all_dirs.sort(key=lambda x: (-x[1], x[0]))
    
    total_files = 0
    total_duplicate_groups = 0
    total_moved = 0
    
    print(f"\nğŸ” æ‰«æç›®å½•: {source_dir}")
    
    # éå†å¤„ç†æ¯ä¸ªç›®å½•
    with tqdm(total=len(all_dirs), desc="å¤„ç†ç›®å½•", unit="dir") as pbar:
        for dir_path, depth in all_dirs:
            files, duplicates, moved = process_directory(dir_path, source_dir, trash_dir)
            total_files += files
            total_duplicate_groups += duplicates
            total_moved += moved
            pbar.update(1)
    
    # æ‰“å°æ€»ä½“ç»Ÿè®¡ä¿¡æ¯
    print(f"\nâœ¨ å¤„ç†å®Œæˆ:")
    print(f"- æ‰«æäº† {total_files} ä¸ªå‹ç¼©æ–‡ä»¶")
    print(f"- å‘ç°äº† {total_duplicate_groups} ç»„é‡å¤æ–‡ä»¶")
    print(f"- ç§»åŠ¨äº† {total_moved} ä¸ªé‡å¤æ–‡ä»¶åˆ° {trash_dir}")

if __name__ == "__main__":
    source_directory = r"E:\1EHV"
    trash_directory = os.path.join(source_directory, "trash")
    process_duplicates(source_directory, trash_directory) 