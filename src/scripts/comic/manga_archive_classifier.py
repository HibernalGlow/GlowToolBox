import os
import sys
import re
import subprocess
from pathlib import Path
import shutil
from datetime import datetime
import tempfile
import argparse
import time
import threading
from concurrent.futures import ThreadPoolExecutor
from queue import Queue
from collections import defaultdict
from rapidfuzz import fuzz, process
import signal
import functools
from opencc import OpenCC
from diff_match_patch import diff_match_patch
import difflib
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from nodes.tui.textual_preset import create_config_app

# å¯¼å…¥è‡ªå®šä¹‰å·¥å…·
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from nodes.tui.rich_logger import RichProgressHandler
# from utils.file_operation_monitor import init_file_monitor  # ä½¿ç”¨å…¨å±€æ–‡ä»¶ç›‘æ§

# # åˆå§‹åŒ–æ–‡ä»¶ç›‘æ§å™¨
# monitor = init_file_monitor()

# åˆå§‹åŒ–å…¨å±€æ—¥å¿—å¤„ç†å™¨
global_handler = None

def get_handler():
    """è·å–å…¨å±€æ—¥å¿—å¤„ç†å™¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„"""
    global global_handler
    if global_handler is None:
        # è‡ªå®šä¹‰å¸ƒå±€é…ç½®
        layout_config = {
            "stats": {"size": 3, "title": "å¤„ç†è¿›åº¦"},
            "current_task": {"size": 2, "title": "å½“å‰ä»»åŠ¡"},
            "archive_process": {"size": 3, "title": "å‹ç¼©åŒ…å¤„ç†"},
            "folder_process": {"size": 3, "title": "æ–‡ä»¶å¤¹å¤„ç†"},
            "series_extract": {"size": 4, "title": "ç³»åˆ—æå–"},  # æ–°å¢ç³»åˆ—æå–é¢æ¿
            "post_process": {"size": 3, "title": "åç»­å¤„ç†"},
            "update_log": {"size": 6, "title": "æ›´æ–°æ—¥å¿—"}
        }
        
        # è‡ªå®šä¹‰æ ·å¼é…ç½®
        style_config = {
            "border_style": "cyan",
            "title_style": "yellow bold",
            "padding": (0, 1),
            # ä¸ºæ¯ä¸ªé¢æ¿è®¾ç½®ä¸åŒçš„é¢œè‰²
            "panel_styles": {
                "stats": "green",
                "current_task": "blue",
                "archive_process": "magenta",
                "folder_process": "cyan",
                "series_extract": "yellow",  # æ–°å¢é¢æ¿çš„é¢œè‰²
                "post_process": "yellow",
                "update_log": "white"
            }
        }
        
        global_handler = RichProgressHandler(
            layout_config=layout_config,
            style_config=style_config
        )
        global_handler.__enter__()
    return global_handler

def close_handler():
    """å…³é—­å…¨å±€æ—¥å¿—å¤„ç†å™¨"""
    global global_handler
    if global_handler is not None:
        global_handler.__exit__(None, None, None)
        global_handler = None

# åˆå§‹åŒ–OpenCCè½¬æ¢å™¨
cc_t2s = OpenCC('t2s')  # ç¹ä½“è½¬ç®€ä½“
cc_s2t = OpenCC('s2t')  # ç®€ä½“è½¬ç¹ä½“

def normalize_chinese(text):
    """æ ‡å‡†åŒ–ä¸­æ–‡æ–‡æœ¬ï¼ˆç»Ÿä¸€è½¬æ¢ä¸ºç®€ä½“ï¼‰"""
    # return cc_t2s.convert(text)
    return text
    
# è®¾ç½®æ–‡ä»¶ç³»ç»Ÿç¼–ç 
if sys.platform == 'win32':
    try:
        import win32api
        def win32_path_exists(path):
            try:
                win32api.GetFileAttributes(path)
                return True
            except:
                print("æœªå®‰è£…win32apiæ¨¡å—ï¼ŒæŸäº›è·¯å¾„å¯èƒ½æ— æ³•æ­£ç¡®å¤„ç†")
                win32_path_exists = os.path.exists
    except ImportError:
        print("æœªå®‰è£…win32apiæ¨¡å—ï¼ŒæŸäº›è·¯å¾„å¯èƒ½æ— æ³•æ­£ç¡®å¤„ç†")
        win32_path_exists = os.path.exists

# å®šä¹‰æ”¯æŒçš„å›¾ç‰‡æ‰©å±•åï¼ˆæ‰©å±•æ”¯æŒæ›´å¤šæ ¼å¼ï¼‰
IMAGE_EXTENSIONS = {
    '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp',
    '.jxl', '.avif', '.heic', '.heif', '.jfif',
    '.tiff', '.tif', '.psd', '.xcf'
}

# å®šä¹‰ç³»åˆ—å‰ç¼€é›†åˆ
SERIES_PREFIXES = {
    '[#s]',  # æ ‡å‡†ç³»åˆ—æ ‡è®°
    '#',     # ç®€å•ç³»åˆ—æ ‡è®°
}

# å®šä¹‰è·¯å¾„é»‘åå•å…³é”®è¯
PATH_BLACKLIST = {
    'ç”»é›†',
    '01è§†é¢‘',
    '02åŠ¨å›¾',
    'æŸåå‹ç¼©åŒ…',
}

# å®šä¹‰ç³»åˆ—æå–é»‘åå•è§„åˆ™
SERIES_BLACKLIST_PATTERNS = [
    r'ç”»é›†',                # ç”»é›†
    r'fanbox',     # artbook/art bookï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    r'pixiv',    # artworks/art worksï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    r'ãƒ»',          # æ’ç”»é›†ï¼ˆæ—¥æ–‡ï¼‰
    r'æ‚å›¾åˆé›†',           # æ’ç”»é›†ï¼ˆä¸­æ–‡ï¼‰
    r'01è§†é¢‘',
    r'02åŠ¨å›¾',
    r'ä½œå“é›†',             # ä½œå“é›†
    r'01è§†é¢‘',
    r'02åŠ¨å›¾',
    r'æŸåå‹ç¼©åŒ…',
]

def is_series_blacklisted(filename):
    """æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åœ¨ç³»åˆ—æå–é»‘åå•ä¸­"""
    for pattern in SERIES_BLACKLIST_PATTERNS:
        if re.search(pattern, filename, re.IGNORECASE):
            return True
    return False

def is_path_blacklisted(path):
    """æ£€æŸ¥è·¯å¾„æ˜¯å¦åœ¨é»‘åå•ä¸­"""
    # è½¬æ¢ä¸ºå°å†™è¿›è¡Œæ¯”è¾ƒ
    path_lower = path.lower()
    return any(keyword.lower() in path_lower for keyword in PATH_BLACKLIST)

class TimeoutError(Exception):
    """è¶…æ—¶å¼‚å¸¸"""
    pass

def timeout(seconds):
    """è¶…æ—¶è£…é¥°å™¨"""
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            def handler(signum, frame):
                raise TimeoutError(f"å‡½æ•°æ‰§è¡Œè¶…æ—¶ ({seconds}ç§’)")

            # è®¾ç½®ä¿¡å·å¤„ç†å™¨
            if sys.platform != 'win32':  # Unixç³»ç»Ÿä½¿ç”¨ä¿¡å·
                original_handler = signal.signal(signal.SIGALRM, handler)
                signal.alarm(seconds)
            else:  # Windowsç³»ç»Ÿä½¿ç”¨çº¿ç¨‹
                timer = threading.Timer(seconds, lambda: threading._shutdown())
                timer.start()

            try:
                result = func(*args, **kwargs)
            finally:
                if sys.platform != 'win32':  # Unixç³»ç»Ÿ
                    signal.alarm(0)
                    signal.signal(signal.SIGALRM, original_handler)
                else:  # Windowsç³»ç»Ÿ
                    timer.cancel()

            return result
        return wrapper
    return decorator

@timeout(60)
def run_7z_command(command, archive_path, operation="", additional_args=None, handler=None):
    """è¿è¡Œ7zå‘½ä»¤å¹¶è¿”å›è¾“å‡º"""
    try:
        # åŸºç¡€å‘½ä»¤
        cmd = ['7z', command]
        if additional_args:
            cmd.extend(additional_args)
        cmd.append(archive_path)
        
        # è¿è¡Œå‘½ä»¤å¹¶æ•è·è¾“å‡º
        # ä½¿ç”¨cp932ç¼–ç (æ—¥æ–‡Windowsé»˜è®¤ç¼–ç )æ¥å¤„ç†è¾“å‡º
        result = subprocess.run(cmd, capture_output=True, text=False, timeout=55)  # è®¾ç½®subprocessè¶…æ—¶ä¸º55ç§’
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨cp932è§£ç 
            output = result.stdout.decode('cp932')
        except UnicodeDecodeError:
            try:
                # å¦‚æœcp932å¤±è´¥ï¼Œå°è¯•utf-8
                output = result.stdout.decode('utf-8')
            except UnicodeDecodeError:
                # å¦‚æœéƒ½å¤±è´¥ï¼Œä½¿ç”¨errors='replace'æ¥æ›¿æ¢æ— æ³•è§£ç çš„å­—ç¬¦
                output = result.stdout.decode('utf-8', errors='replace')
        
        return output if output else ""
    except subprocess.TimeoutExpired:
        raise TimeoutError(f"7zå‘½ä»¤æ‰§è¡Œè¶…æ—¶: {archive_path}")
    except Exception as e:
        if handler:
            handler.update_panel("update_log", f"âŒ æ‰§è¡Œ7zå‘½ä»¤æ—¶å‡ºé”™ {archive_path}: {str(e)}")
        return ""

@timeout(60)
def is_archive_corrupted(archive_path):
    """æ£€æŸ¥å‹ç¼©åŒ…æ˜¯å¦æŸå"""
    try:
        # ä½¿ç”¨7zæµ‹è¯•å‹ç¼©åŒ…å®Œæ•´æ€§
        cmd = ['7z', 't', archive_path]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=55)
        return result.returncode != 0
    except subprocess.TimeoutExpired:
        raise TimeoutError(f"æ£€æŸ¥å‹ç¼©åŒ…å®Œæ•´æ€§è¶…æ—¶: {archive_path}")
    except Exception:
        return True

@timeout(60)
def count_images_in_archive(archive_path, handler=None):
    """ä½¿ç”¨7zçš„åˆ—è¡¨æ¨¡å¼ç»Ÿè®¡å‹ç¼©åŒ…ä¸­çš„å›¾ç‰‡æ•°é‡"""
    try:
        if handler is None:
            handler = get_handler()
            
        # é¦–å…ˆæ£€æŸ¥å‹ç¼©åŒ…æ˜¯å¦æŸå
        if is_archive_corrupted(archive_path):
            handler.update_panel("update_log", f"âš ï¸ å‹ç¼©åŒ…å·²æŸåï¼Œè·³è¿‡å¤„ç†: {archive_path}")
            return -1
            
        # ä½¿ç”¨7zçš„åˆ—è¡¨å‘½ä»¤ï¼Œæ·»åŠ -sltå‚æ•°æ¥è·å–è¯¦ç»†ä¿¡æ¯
        output = run_7z_command('l', archive_path, additional_args=['-slt'], handler=handler)
        
        # ç¡®ä¿è¾“å‡ºä¸ä¸ºç©º
        if not output:
            handler.update_panel("update_log", f"âŒ æ— æ³•è·å–å‹ç¼©åŒ…å†…å®¹åˆ—è¡¨: {archive_path}")
            return 0
            
        # ä½¿ç”¨æ›´é«˜æ•ˆçš„æ–¹å¼ç»Ÿè®¡å›¾ç‰‡æ•°é‡
        image_count = sum(1 for ext in IMAGE_EXTENSIONS if ext in output.lower())
        
        # æ·»åŠ åˆ°æ›´æ–°æ—¥å¿—
        handler.update_panel("update_log", f"ğŸ“¦ å‹ç¼©åŒ… '{os.path.basename(archive_path)}' ä¸­åŒ…å« {image_count} å¼ å›¾ç‰‡")
        
        return image_count
    except TimeoutError as e:
        if handler:
            handler.update_panel("update_log", f"âŒ å¤„ç†å‹ç¼©åŒ…è¶…æ—¶ {archive_path}: {str(e)}")
        return -1
    except Exception as e:
        if handler:
            handler.update_panel("update_log", f"âŒ å¤„ç†å‹ç¼©åŒ…æ—¶å‡ºé”™ {archive_path}: {str(e)}")
        return -1

def is_archive(path):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºæ”¯æŒçš„å‹ç¼©åŒ…æ ¼å¼"""
    return Path(path).suffix.lower() in {'.zip', '.rar', '.7z', '.cbz', '.cbr'}

# å®šä¹‰åˆ†ç±»è§„åˆ™
CATEGORY_RULES = {
    "1. åŒäººå¿—": {
        "patterns": [
            r'\[C\d+\]',           # [C97], [C98] ç­‰
            r'\(C\d+\)',           # (C97), (C98) ç­‰
            r'ã‚³ãƒŸã‚±\d+',           # ã‚³ãƒŸã‚±97 ç­‰
            r'COMIC\s*MARKET',      # COMIC MARKET
            r'COMIC1',              # COMIC1
            r'åŒäººèªŒ',              # åŒäººå¿—ï¼ˆæ—¥æ–‡ï¼‰
            r'åŒäººå¿—',              # åŒäººå¿—ï¼ˆä¸­æ–‡ï¼‰
            r'ã‚³ãƒŸã‚±',              # ã‚³ãƒŸã‚±
            r'ã‚³ãƒŸãƒƒã‚¯ãƒãƒ¼ã‚±ãƒƒãƒˆ',   # ã‚³ãƒŸãƒƒã‚¯ãƒãƒ¼ã‚±ãƒƒãƒˆ
            r'ä¾‹å¤§ç¥­',              # ä¾‹å¤§ç¥­
            r'ã‚µãƒ³ã‚¯ãƒª',            # ã‚µãƒ³ã‚¯ãƒª
            r'(?i)doujin',         # doujinï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            r'COMIC1â˜†\d+',         # COMIC1â˜†17ç­‰
        ],
        "exclude_patterns": [
            r'ç”»é›†',                # æ’é™¤ç”»é›†
            r'artbook',
            r'art\s*works',
            r'01è§†é¢‘',
            r'02åŠ¨å›¾',
            r'art\s*works'
        ]
    },
    "2. å•†ä¸šå¿—": {
        "patterns": [
            r'(?i)magazine',        # magazineï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            r'(?i)COMIC',      # commercialï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            r'é›‘èªŒ',                # æ‚å¿—ï¼ˆæ—¥æ–‡ï¼‰
            r'æ‚å¿—',                # æ‚å¿—ï¼ˆä¸­æ–‡ï¼‰
            r'å•†ä¸š',
            r'é€±åˆŠ',                # å‘¨åˆŠ
            r'æœˆåˆŠ',                # æœˆåˆŠ
            r'æœˆå·',                # æœˆå·
            r'COMIC\s*REX',         # COMIC REX
            r'ã‚³ãƒŸãƒƒã‚¯',      # é’å¹´JUMP
            r'ãƒ¤ãƒ³ã‚°ãƒã‚¬ã‚¸ãƒ³',      # é’å¹´Magazine
            r'\d{4}å¹´\d{1,2}æœˆå·',  # yyyyå¹´mæœˆå·
        ],
        "exclude_patterns": [
            r'åŒäºº',
            r'(?i)doujin',
            r'å˜è¡Œæœ¬',
            r'ç”»é›†'
        ]
    },
    "3. å•è¡Œæœ¬": {
        "patterns": [
            r'å˜è¡Œæœ¬',              # å•è¡Œæœ¬ï¼ˆæ—¥æ–‡ï¼‰
            r'å•è¡Œæœ¬',              # å•è¡Œæœ¬ï¼ˆä¸­æ–‡ï¼‰
            r'(?i)tankoubon',       # tankoubonï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            r'ç¬¬\d+å·»',             # ç¬¬Xå·»
            r'vol\.?\d+',          # vol.X æˆ– volX
            r'volume\s*\d+'        # volume X
        ],
        "exclude_patterns": [
            r'ç”»é›†',
            r'artbook',
            r'art\s*works'
        ]
    },
    "4. ç”»é›†": {
        "patterns": [
            r'ç”»é›†',                # ç”»é›†
            r'(?i)art\s*book',     # artbook/art bookï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            r'(?i)art\s*works',    # artworks/art worksï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            r'ã‚¤ãƒ©ã‚¹ãƒˆé›†',          # æ’ç”»é›†ï¼ˆæ—¥æ–‡ï¼‰
            r'æ‚å›¾åˆé›†',              # æ’ç”»é›†ï¼ˆä¸­æ–‡ï¼‰
            r'ä½œå“é›†',              # ä½œå“é›†
            r'illustrations?',      # illustration/illustrations
            r'(?i)illust\s*collection'  # Illust Collection
        ],
        "exclude_patterns": []
    },
    "5. åŒäººCG": {
        "patterns": [
            r'åŒäººCG',
        ],
        "exclude_patterns": []
    }
}

def get_category(path, handler=None):
    """æ ¹æ®è·¯å¾„ååˆ¤æ–­ç±»åˆ«ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡ŒåŒ¹é…"""
    if handler is None:
        handler = get_handler()
        
    filename = os.path.basename(path)
    
    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºå‹ç¼©åŒ…
    if not is_archive(path):
        return "æœªåˆ†ç±»"
        
    # æ£€æŸ¥å‹ç¼©åŒ…æ˜¯å¦æŸå
    if is_archive_corrupted(path):
        return "æŸå"
        
    # æ£€æŸ¥æ˜¯å¦ä¸ºç”»é›†
    for pattern in CATEGORY_RULES["4. ç”»é›†"]["patterns"]:
        if re.search(pattern, filename, re.IGNORECASE):
            return "4. ç”»é›†"
    
    # ç»Ÿè®¡å‹ç¼©åŒ…ä¸­çš„å›¾ç‰‡æ•°é‡
    image_count = count_images_in_archive(path, handler)
    if image_count == -1:  # è¡¨ç¤ºå‹ç¼©åŒ…æŸå
        return "æŸå"
        
    handler.update_panel("update_log", f"å‹ç¼©åŒ… '{filename}' ä¸­åŒ…å« {image_count} å¼ å›¾ç‰‡")
    
    # å¦‚æœå›¾ç‰‡æ•°é‡è¶…è¿‡100ä¸”ä¸æ˜¯ç”»é›†ï¼Œæ£€æŸ¥å…¶ä»–åˆ†ç±»è§„åˆ™
    if image_count >= 100:
        # æ£€æŸ¥å…¶ä»–æ˜ç¡®çš„åˆ†ç±»è§„åˆ™
        for category, rules in CATEGORY_RULES.items():
            if category == "4. ç”»é›†":  # è·³è¿‡ç”»é›†åˆ†ç±»
                continue
                
            # æ£€æŸ¥æ’é™¤è§„åˆ™
            excluded = False
            for exclude_pattern in rules["exclude_patterns"]:
                if re.search(exclude_pattern, filename, re.IGNORECASE):
                    excluded = True
                    break
            
            if excluded:
                continue
                
            # æ£€æŸ¥åŒ…å«è§„åˆ™
            for pattern in rules["patterns"]:
                if re.search(pattern, filename, re.IGNORECASE):
                    return category
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…å…¶ä»–è§„åˆ™ï¼Œåˆ™å½’ç±»ä¸ºå•è¡Œæœ¬
        return "3. å•è¡Œæœ¬"
    
    # å¦‚æœå›¾ç‰‡æ•°é‡ä¸è¶…è¿‡100ï¼Œæ£€æŸ¥å…¶ä»–åˆ†ç±»è§„åˆ™
    for category, rules in CATEGORY_RULES.items():
        if category == "4. ç”»é›†":  # è·³è¿‡ç”»é›†åˆ†ç±»ï¼Œå› ä¸ºå·²ç»æ£€æŸ¥è¿‡äº†
            continue
            
        # æ£€æŸ¥æ’é™¤è§„åˆ™
        excluded = False
        for exclude_pattern in rules["exclude_patterns"]:
            if re.search(exclude_pattern, filename, re.IGNORECASE):
                excluded = True
                break
        
        if excluded:
            continue
            
        # æ£€æŸ¥åŒ…å«è§„åˆ™
        for pattern in rules["patterns"]:
            if re.search(pattern, filename, re.IGNORECASE):
                return category
                
    return "æœªåˆ†ç±»"

def create_category_folders(base_path, handler=None):
    """åœ¨æŒ‡å®šè·¯å¾„åˆ›å»ºåˆ†ç±»æ–‡ä»¶å¤¹"""
    # åˆ›å»ºåˆ†ç±»æ–‡ä»¶å¤¹
    for category in CATEGORY_RULES.keys():
        category_path = os.path.join(base_path, category)
        if not os.path.exists(category_path):
            os.makedirs(category_path)
            if handler:
                handler.update_panel("update_log", f"ğŸ“ åˆ›å»ºåˆ†ç±»æ–‡ä»¶å¤¹: {category}")
    
    # åˆ›å»ºæŸåå‹ç¼©åŒ…æ–‡ä»¶å¤¹
    corrupted_path = os.path.join(base_path, "æŸåå‹ç¼©åŒ…")
    if not os.path.exists(corrupted_path):
        os.makedirs(corrupted_path)
        if handler:
            handler.update_panel("update_log", f"ğŸ“ åˆ›å»ºæŸåå‹ç¼©åŒ…æ–‡ä»¶å¤¹")

def move_file_to_category(file_path, category, handler=None):
    """å°†æ–‡ä»¶ç§»åŠ¨åˆ°å¯¹åº”çš„åˆ†ç±»æ–‡ä»¶å¤¹"""
    if category == "æœªåˆ†ç±»":
        if handler:
            handler.update_panel("update_log", f"æ–‡ä»¶ '{file_path}' æœªèƒ½åŒ¹é…ä»»ä½•åˆ†ç±»è§„åˆ™ï¼Œä¿æŒåŸä½ç½®")
        return
        
    target_dir = os.path.join(os.path.dirname(file_path), category)
    target_path = os.path.join(target_dir, os.path.basename(file_path))
    
    if not os.path.exists(target_path):
        shutil.move(file_path, target_path)
        if handler:
            handler.update_panel("update_log", f"å·²ç§»åŠ¨åˆ°: {target_path}")
    else:
        if handler:
            handler.update_panel("update_log", f"ç›®æ ‡è·¯å¾„å·²å­˜åœ¨æ–‡ä»¶: {target_path}")

def move_corrupted_archive(file_path, base_path, handler=None):
    """ç§»åŠ¨æŸåçš„å‹ç¼©åŒ…åˆ°æŸåå‹ç¼©åŒ…æ–‡ä»¶å¤¹ï¼Œä¿æŒåŸæœ‰ç›®å½•ç»“æ„"""
    try:
        # è·å–ç›¸å¯¹è·¯å¾„
        rel_path = os.path.relpath(os.path.dirname(file_path), base_path)
        # æ„å»ºç›®æ ‡è·¯å¾„
        corrupted_base = os.path.join(base_path, "æŸåå‹ç¼©åŒ…")
        target_dir = os.path.join(corrupted_base, rel_path)
        
        # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
        os.makedirs(target_dir, exist_ok=True)
        
        # æ„å»ºç›®æ ‡æ–‡ä»¶è·¯å¾„
        target_path = os.path.join(target_dir, os.path.basename(file_path))
        
        # å¦‚æœç›®æ ‡è·¯å¾„å·²å­˜åœ¨ï¼Œæ·»åŠ æ•°å­—åç¼€
        if os.path.exists(target_path):
            base, ext = os.path.splitext(target_path)
            counter = 1
            while os.path.exists(f"{base}_{counter}{ext}"):
                counter += 1
            target_path = f"{base}_{counter}{ext}"
        
        # ç§»åŠ¨æ–‡ä»¶
        shutil.move(file_path, target_path)
        if handler:
            handler.update_panel("update_log", f"ğŸ“¦ å·²ç§»åŠ¨æŸåå‹ç¼©åŒ…: {os.path.basename(file_path)} -> æŸåå‹ç¼©åŒ…/{rel_path}")
            
    except Exception as e:
        if handler:
            handler.update_panel("update_log", f"âŒ ç§»åŠ¨æŸåå‹ç¼©åŒ…å¤±è´¥ {file_path}: {str(e)}")

def process_single_file(abs_path, handler=None):
    """å¤„ç†å•ä¸ªæ–‡ä»¶"""
    try:
        if not os.path.exists(abs_path):
            if handler:
                handler.update_panel("update_log", f"âŒ è·¯å¾„ä¸å­˜åœ¨: {abs_path}")
            return
            
        if handler:
            handler.update_panel("current_task", f"å¤„ç†æ–‡ä»¶: {os.path.basename(abs_path)}")
            handler.update_panel("archive_process", f"åˆ†æ: {os.path.basename(abs_path)}")
        
        # ç¡®ä¿åˆ†ç±»æ–‡ä»¶å¤¹å­˜åœ¨
        create_category_folders(os.path.dirname(abs_path))
        
        # è·å–æ–‡ä»¶åˆ†ç±»
        category = get_category(abs_path)
        
        # å¦‚æœæ˜¯æŸåçš„å‹ç¼©åŒ…ï¼Œç§»åŠ¨åˆ°æŸåå‹ç¼©åŒ…æ–‡ä»¶å¤¹
        if category == "æŸå":
            if handler:
                handler.update_panel("update_log", f"âš ï¸ å‹ç¼©åŒ…å·²æŸå: {os.path.basename(abs_path)}")
                handler.update_panel("archive_process", f"âŒ æŸå: {os.path.basename(abs_path)}")
            move_corrupted_archive(abs_path, os.path.dirname(abs_path), handler)
            return
        
        # ç§»åŠ¨æ–‡ä»¶åˆ°å¯¹åº”åˆ†ç±»
        move_file_to_category(abs_path, category, handler)
        
        if handler:
            handler.update_panel("archive_process", f"âœ… å®Œæˆ: {os.path.basename(abs_path)} -> {category}")
        
    except Exception as e:
        if handler:
            handler.update_panel("update_log", f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™ {abs_path}: {str(e)}")
            handler.update_panel("archive_process", f"âŒ é”™è¯¯: {os.path.basename(abs_path)}")

def normalize_filename(filename):
    """å»é™¤æ–‡ä»¶åä¸­çš„åœ†æ‹¬å·ã€æ–¹æ‹¬å·åŠå…¶å†…å®¹ï¼Œè¿”å›è§„èŒƒåŒ–çš„æ–‡ä»¶å"""
    # å»æ‰æ‰©å±•å
    name = os.path.splitext(filename)[0]
    
    # å»é™¤æ–¹æ‹¬å·åŠå…¶å†…å®¹
    name = re.sub(r'\[[^\]]*\]', '', name)
    # å»é™¤åœ†æ‹¬å·åŠå…¶å†…å®¹
    name = re.sub(r'\([^)]*\)', '', name)
    
    # å»é™¤å·å·æ ‡è®°ï¼Œä½†ä¿ç•™æ•°å­—
    name = re.sub(r'vol\.?|ç¬¬|å·»|å·', '', name, flags=re.IGNORECASE)
    
    # å»é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ ‡ç‚¹
    name = re.sub(r'[\s!ï¼?ï¼Ÿ_~ï½]+', ' ', name)
    name = name.strip()
    
    return name

# ç›¸ä¼¼åº¦é…ç½®
SIMILARITY_CONFIG = {
    'THRESHOLD': 75,  # åŸºæœ¬ç›¸ä¼¼åº¦é˜ˆå€¼
    'LENGTH_DIFF_MAX': 0.3,  # é•¿åº¦å·®å¼‚æœ€å¤§å€¼
    'RATIO_THRESHOLD': 75,  # å®Œå…¨åŒ¹é…é˜ˆå€¼
    'PARTIAL_THRESHOLD': 85,  # éƒ¨åˆ†åŒ¹é…é˜ˆå€¼
    'TOKEN_THRESHOLD': 80,  # æ ‡è®°åŒ¹é…é˜ˆå€¼
}

def is_in_series_folder(file_path):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»åœ¨ç³»åˆ—æ–‡ä»¶å¤¹å†…"""
    parent_dir = os.path.dirname(file_path)
    parent_name = os.path.basename(parent_dir)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç³»åˆ—æ ‡è®°
    for prefix in SERIES_PREFIXES:
        if parent_name.startswith(prefix):
            # æå–ç³»åˆ—åç§°å¹¶é‡æ–°ç”¨ get_series_key å¤„ç†
            series_name = parent_name[len(prefix):]  # å»æ‰å‰ç¼€
            parent_key = get_series_key(series_name)
            file_key = get_series_key(os.path.basename(file_path))
            return parent_key == file_key
    
    # å¦‚æœçˆ¶ç›®å½•åç§°æ˜¯æ–‡ä»¶åçš„ä¸€éƒ¨åˆ†ï¼ˆå»é™¤æ•°å­—å’Œæ‹¬å·åï¼‰ï¼Œåˆ™è®¤ä¸ºå·²åœ¨ç³»åˆ—æ–‡ä»¶å¤¹å†…
    parent_key = get_series_key(parent_name)
    file_key = get_series_key(os.path.basename(file_path))
    
    if parent_key and parent_key in file_key:
        return True
    return False

def calculate_similarity(str1, str2, handler=None):
    """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦"""
    # æ ‡å‡†åŒ–ä¸­æ–‡ï¼ˆè½¬æ¢ä¸ºç®€ä½“ï¼‰åå†æ¯”è¾ƒ
    str1 = normalize_chinese(str1)
    str2 = normalize_chinese(str2)
    
    ratio = fuzz.ratio(str1.lower(), str2.lower())
    partial = fuzz.partial_ratio(str1.lower(), str2.lower())
    token = fuzz.token_sort_ratio(str1.lower(), str2.lower())
    
    max_similarity = max(ratio, partial, token)
    if handler and max_similarity >= SIMILARITY_CONFIG['THRESHOLD']:
        handler.update_panel("update_log", f"ğŸ” ç›¸ä¼¼åº¦: {max_similarity}%")
    return max_similarity

def is_similar_to_existing_folder(dir_path, series_name, handler=None):
    """æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸ä¼¼çš„æ–‡ä»¶å¤¹åç§°"""
    try:
        existing_folders = [d for d in os.listdir(dir_path) 
                          if os.path.isdir(os.path.join(dir_path, d))]
    except Exception as e:
        if handler:
            handler.update_panel("update_log", f"âŒ è¯»å–ç›®å½•å¤±è´¥: {dir_path}")
        return False
    
    series_key = get_series_key(series_name, handler)
    
    for folder in existing_folders:
        # æ£€æŸ¥æ‰€æœ‰æ”¯æŒçš„ç³»åˆ—å‰ç¼€
        is_series_folder = False
        folder_name = folder
        for prefix in SERIES_PREFIXES:
            if folder.startswith(prefix):
                # å¯¹å·²æœ‰çš„ç³»åˆ—æ–‡ä»¶å¤¹ä½¿ç”¨ç›¸åŒçš„å¤„ç†æ ‡å‡†
                folder_name = folder[len(prefix):]  # å»æ‰å‰ç¼€
                is_series_folder = True
                break
        
        if is_series_folder:
            folder_key = get_series_key(folder_name, handler)
            
            # å¦‚æœç³»åˆ—é”®å®Œå…¨ç›¸åŒï¼Œç›´æ¥è¿”å›True
            if series_key == folder_key:
                if handler:
                    handler.update_panel("update_log", f"ğŸ“ æ‰¾åˆ°ç›¸åŒç³»åˆ—æ–‡ä»¶å¤¹: '{folder}'")
                return True
            
            # å¦åˆ™è®¡ç®—ç›¸ä¼¼åº¦
            similarity = calculate_similarity(series_key, folder_key, handler)
            if similarity >= SIMILARITY_CONFIG['THRESHOLD']:
                if handler:
                    handler.update_panel("update_log", f"ğŸ“ æ‰¾åˆ°ç›¸ä¼¼æ–‡ä»¶å¤¹: '{folder}'")
                return True
        else:
            # å¯¹éç³»åˆ—æ–‡ä»¶å¤¹ä½¿ç”¨åŸæœ‰çš„ç›¸ä¼¼åº¦æ£€æŸ¥
            similarity = calculate_similarity(series_name, folder, handler)
            if similarity >= SIMILARITY_CONFIG['THRESHOLD']:
                if handler:
                    handler.update_panel("update_log", f"ğŸ“ æ‰¾åˆ°ç›¸ä¼¼æ–‡ä»¶å¤¹: '{folder}'")
                return True
    return False

def get_series_key(filename, handler=None):
    """è·å–ç”¨äºç³»åˆ—æ¯”è¾ƒçš„é”®å€¼"""
    if handler:
        handler.update_panel("series_extract", f"å¤„ç†æ–‡ä»¶: {filename}")
    
    # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿçš„å¯¹æ¯”ç»„ï¼ŒåŒ…å«å½“å‰æ–‡ä»¶å’Œè‡ªèº«çš„å‰¯æœ¬
    # è¿™æ ·å¯ä»¥åˆ©ç”¨ find_series_groups çš„é€»è¾‘æ¥æå–ç³»åˆ—åç§°
    test_group = [filename, filename]
    series_groups = find_series_groups(test_group, handler)
    
    # å¦‚æœèƒ½æ‰¾åˆ°ç³»åˆ—åç§°ï¼Œä½¿ç”¨å®ƒ
    if series_groups:
        series_name = next(iter(series_groups.keys()))
        if handler:
            handler.update_panel("series_extract", f"æ‰¾åˆ°ç³»åˆ—åç§°: {series_name}")
        return series_name
    
    # å¦‚æœæ‰¾ä¸åˆ°ç³»åˆ—åç§°ï¼Œé€€å›åˆ°åŸºæœ¬çš„é¢„å¤„ç†
    name = preprocess_filename(filename)
    name = normalize_chinese(name)
    
    if handler:
        handler.update_panel("series_extract", f"ä½¿ç”¨é¢„å¤„ç†ç»“æœ: {name}")
    
    return name.strip()

def update_series_folder_name(old_path, handler=None):
    """æ›´æ–°ç³»åˆ—æ–‡ä»¶å¤¹åç§°ä¸ºæœ€æ–°æ ‡å‡†"""
    try:
        dir_name = os.path.basename(old_path)
        is_series = False
        prefix_used = None
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç³»åˆ—æ–‡ä»¶å¤¹
        for prefix in SERIES_PREFIXES:
            if dir_name.startswith(prefix):
                is_series = True
                prefix_used = prefix
                break
                
        if not is_series:
            return False
            
        # æå–åŸå§‹ç³»åˆ—å
        old_series_name = dir_name[len(prefix_used):]
        # ä½¿ç”¨æ–°æ ‡å‡†å¤„ç†ç³»åˆ—å
        new_series_name = get_series_key(old_series_name)
        
        if not new_series_name or new_series_name == old_series_name:
            return False
            
        # åˆ›å»ºæ–°è·¯å¾„ï¼ˆä½¿ç”¨æ ‡å‡†ç³»åˆ—æ ‡è®°[#s]ï¼‰
        new_path = os.path.join(os.path.dirname(old_path), f'[#s]{new_series_name}')
        
        # å¦‚æœæ–°è·¯å¾„å·²å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºä¸åŒè·¯å¾„
        if os.path.exists(new_path) and os.path.abspath(new_path) != os.path.abspath(old_path):
            if handler:
                handler.update_panel("update_log", f"âš ï¸ ç›®æ ‡è·¯å¾„å·²å­˜åœ¨: {new_path}")
            return False
            
        # é‡å‘½åæ–‡ä»¶å¤¹
        os.rename(old_path, new_path)
        if handler:
            handler.update_panel("update_log", f"ğŸ“ æ›´æ–°ç³»åˆ—æ–‡ä»¶å¤¹åç§°: {dir_name} -> [#s]{new_series_name}")
        return True
        
    except Exception as e:
        if handler:
            handler.update_panel("update_log", f"âŒ æ›´æ–°ç³»åˆ—æ–‡ä»¶å¤¹åç§°å¤±è´¥ {old_path}: {str(e)}")
        return False

def update_all_series_folders(directory_path, handler=None):
    """æ›´æ–°ç›®å½•ä¸‹æ‰€æœ‰çš„ç³»åˆ—æ–‡ä»¶å¤¹åç§°"""
    try:
        updated_count = 0
        for root, dirs, _ in os.walk(directory_path):
            for dir_name in dirs:
                if dir_name.startswith('[#s]'):
                    full_path = os.path.join(root, dir_name)
                    if update_series_folder_name(full_path, handler):
                        updated_count += 1
        
        if handler and updated_count > 0:
            handler.update_panel("update_log", f"âœ¨ æ›´æ–°äº† {updated_count} ä¸ªç³»åˆ—æ–‡ä»¶å¤¹åç§°")
            
        return updated_count
        
    except Exception as e:
        if handler:
            handler.update_panel("update_log", f"âŒ æ›´æ–°ç³»åˆ—æ–‡ä»¶å¤¹å¤±è´¥: {str(e)}")
        return 0

def preprocess_filenames(files, handler=None):
    """é¢„å¤„ç†æ‰€æœ‰æ–‡ä»¶å"""
    file_keys = {}
    for file_path in files:
        key = get_series_key(os.path.basename(file_path))
        file_keys[file_path] = key
        if handler:
            handler.update_panel("update_log", f"ğŸ”„ é¢„å¤„ç†: {os.path.basename(file_path)} -> {key}")
    return file_keys

def get_base_filename(filename):
    """è·å–å»é™¤æ‰€æœ‰æ ‡ç­¾åçš„åŸºæœ¬æ–‡ä»¶å"""
    # å»æ‰æ‰©å±•å
    name = os.path.splitext(filename)[0]
    
    # å»é™¤æ‰€æœ‰æ–¹æ‹¬å·åŠå…¶å†…å®¹
    name = re.sub(r'\[[^\]]*\]', '', name)
    # å»é™¤æ‰€æœ‰åœ†æ‹¬å·åŠå…¶å†…å®¹
    name = re.sub(r'\([^)]*\)', '', name)
    # å»é™¤æ‰€æœ‰ç©ºæ ¼å’Œæ ‡ç‚¹
    name = re.sub(r'[\s!ï¼?ï¼Ÿ_~ï½]+', '', name)
    # æ ‡å‡†åŒ–ä¸­æ–‡ï¼ˆè½¬æ¢ä¸ºç®€ä½“ï¼‰
    name = normalize_chinese(name)
    
    return name

def is_essentially_same_file(file1, file2):
    """æ£€æŸ¥ä¸¤ä¸ªæ–‡ä»¶æ˜¯å¦æœ¬è´¨ä¸Šæ˜¯åŒä¸€ä¸ªæ–‡ä»¶ï¼ˆåªæ˜¯æ ‡ç­¾ä¸åŒï¼‰"""
    # è·å–æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„å’Œæ‰©å±•åï¼‰
    name1 = os.path.splitext(os.path.basename(file1))[0]
    name2 = os.path.splitext(os.path.basename(file2))[0]
    
    # å¦‚æœåŸå§‹æ–‡ä»¶åå®Œå…¨ç›¸åŒï¼Œåˆ™è®¤ä¸ºæ˜¯åŒä¸€ä¸ªæ–‡ä»¶
    if name1 == name2:
        return True
        
    # å»é™¤æ‰€æœ‰æ ‡ç­¾ã€ç©ºæ ¼å’Œæ ‡ç‚¹
    base1 = re.sub(r'\[[^\]]*\]|\([^)]*\)', '', name1)  # å»é™¤æ ‡ç­¾
    base2 = re.sub(r'\[[^\]]*\]|\([^)]*\)', '', name2)  # å»é™¤æ ‡ç­¾
    
    # å»é™¤æ‰€æœ‰ç©ºæ ¼å’Œæ ‡ç‚¹
    base1 = re.sub(r'[\s]+', '', base1).lower()
    base2 = re.sub(r'[\s]+', '', base2).lower()
    
    # æ ‡å‡†åŒ–ä¸­æ–‡ï¼ˆè½¬æ¢ä¸ºç®€ä½“ï¼‰
    base1 = normalize_chinese(base1)
    base2 = normalize_chinese(base2)
    
    # å®Œå…¨ç›¸åŒçš„åŸºç¡€åç§°æ‰è®¤ä¸ºæ˜¯åŒä¸€ä¸ªæ–‡ä»¶
    return base1 == base2

def find_similar_files(current_file, files, file_keys, processed_files, handler=None):
    """æŸ¥æ‰¾ä¸å½“å‰æ–‡ä»¶ç›¸ä¼¼çš„æ–‡ä»¶"""
    current_key = file_keys[current_file]
    similar_files = [current_file]
    to_process = set()  # åˆ›å»ºä¸´æ—¶é›†åˆå­˜å‚¨è¦å¤„ç†çš„æ–‡ä»¶
    
    if not current_key.strip():
        return similar_files, to_process
    
    for other_file in files:
        if other_file in processed_files or other_file == current_file:
            continue
            
        if is_in_series_folder(other_file):
            continue
            
        if is_essentially_same_file(current_file, other_file):
            to_process.add(other_file)  # æ·»åŠ åˆ°ä¸´æ—¶é›†åˆ
            continue
            
        other_key = file_keys[other_file]
        if not other_key.strip():
            continue
            
        ratio = fuzz.ratio(current_key.lower(), other_key.lower())
        partial = fuzz.partial_ratio(current_key.lower(), other_key.lower())
        token = fuzz.token_sort_ratio(current_key.lower(), other_key.lower())
        
        len_diff = abs(len(current_key) - len(other_key)) / max(len(current_key), len(other_key))
        
        is_similar = (
            ratio >= SIMILARITY_CONFIG['RATIO_THRESHOLD'] and
            partial >= SIMILARITY_CONFIG['PARTIAL_THRESHOLD'] and
            token >= SIMILARITY_CONFIG['TOKEN_THRESHOLD'] and
            len_diff <= SIMILARITY_CONFIG['LENGTH_DIFF_MAX']
        )
        
        if is_similar:
            if handler:
                handler.update_panel("update_log", f"âœ¨ å‘ç°ç›¸ä¼¼æ–‡ä»¶: {os.path.basename(other_file)} (ç›¸ä¼¼åº¦: {max(ratio, partial, token)}%)")
            similar_files.append(other_file)
            to_process.add(other_file)  # æ·»åŠ åˆ°ä¸´æ—¶é›†åˆ
            
    return similar_files, to_process

def extract_keywords(filename):
    """ä»æ–‡ä»¶åä¸­æå–å…³é”®è¯"""
    # å»æ‰æ‰©å±•åå’Œæ–¹æ‹¬å·å†…å®¹
    name = get_base_filename(filename)
    
    # ä½¿ç”¨å¤šç§åˆ†éš”ç¬¦åˆ†å‰²æ–‡ä»¶å
    separators = r'[\s]+'
    keywords = []
    
    # åˆ†å‰²å‰å…ˆå»é™¤å…¶ä»–æ–¹æ‹¬å·å’Œåœ†æ‹¬å·çš„å†…å®¹
    name = re.sub(r'\[[^\]]*\]|\([^)]*\)', ' ', name)
    
    # åˆ†å‰²å¹¶è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
    parts = [p.strip() for p in re.split(separators, name) if p.strip()]
    
    # å¯¹äºæ¯ä¸ªéƒ¨åˆ†ï¼Œå¦‚æœé•¿åº¦å¤§äº1ï¼Œåˆ™æ·»åŠ åˆ°å…³é”®è¯åˆ—è¡¨
    for part in parts:
        if len(part) > 1:  # å¿½ç•¥å•ä¸ªå­—ç¬¦
            keywords.append(part)
    
    return keywords

def find_keyword_based_groups(remaining_files, file_keys, processed_files, handler=None):
    """åŸºäºå…³é”®è¯æŸ¥æ‰¾ç³»åˆ—ç»„"""
    keyword_groups = defaultdict(list)
    file_keywords = {}
    to_process = set()  # åˆ›å»ºä¸´æ—¶é›†åˆå­˜å‚¨è¦å¤„ç†çš„æ–‡ä»¶
    
    # é¢„å¤„ç†æ–‡ä»¶å…³é”®è¯
    for file_path in remaining_files:
        if file_path in processed_files:
            continue
        keywords = extract_keywords(os.path.basename(file_path))
        if len(keywords) >= 1:
            file_keywords[file_path] = keywords
            # if handler:
                # handler.add_status_log(f"ğŸ” æå–å…³é”®è¯: {os.path.basename(file_path)} -> {', '.join(keywords)}")
    
    def process_file_keywords(args):
        file_path, keywords = args
        if file_path in processed_files:
            return None
            
        current_group = [file_path]
        group_keywords = set(keywords)
        current_to_process = set()  # å½“å‰å¤„ç†çš„æ–‡ä»¶é›†åˆ
        
        for other_path, other_keywords in file_keywords.items():
            if other_path == file_path or other_path in processed_files:
                continue
                
            common_keywords = set(keywords) & set(other_keywords)
            if common_keywords and any(len(k) > 1 for k in common_keywords):
                current_group.append(other_path)
                current_to_process.add(other_path)  # æ·»åŠ åˆ°ä¸´æ—¶é›†åˆ
                group_keywords &= set(other_keywords)
        
        if len(current_group) > 1:
            series_name = max(group_keywords, key=len) if group_keywords else max(keywords, key=len)
            return (series_name, current_group, current_to_process)
        return None
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†å…³é”®è¯åŒ¹é…
    with ThreadPoolExecutor(max_workers=16) as executor:
        results = list(executor.map(process_file_keywords, file_keywords.items()))
    
    for result in results:
        if result:
            series_name, group, current_to_process = result
            if handler:
                handler.update_panel("update_log", f"ğŸ“š å‘ç°ç³»åˆ—: {series_name} ({len(group)}ä¸ªæ–‡ä»¶)")
                for file_path in group:
                    handler.update_panel("update_log", f"  â””â”€ {os.path.basename(file_path)}")
            keyword_groups[series_name] = group
            to_process.update(current_to_process)  # æ›´æ–°æ€»çš„å¤„ç†é›†åˆ
            to_process.add(group[0])
    
    return keyword_groups, to_process

def preprocess_filename(filename):
    """é¢„å¤„ç†æ–‡ä»¶å"""
    # è·å–æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
    name = os.path.basename(filename)
    # å»é™¤æ‰©å±•å
    name = name.rsplit('.', 1)[0]
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç³»åˆ—æ ‡è®°å‰ç¼€ï¼Œå¦‚æœæœ‰åˆ™å»é™¤
    for prefix in SERIES_PREFIXES:
        if name.startswith(prefix):
            name = name[len(prefix):]
            break
            
    # å»é™¤æ–¹æ‹¬å·å†…å®¹
    name = re.sub(r'\[.*?\]', '', name)
    # å»é™¤åœ†æ‹¬å·å†…å®¹
    name = re.sub(r'\(.*?\)', '', name)
    # å»é™¤å¤šä½™ç©ºæ ¼
    name = ' '.join(name.split())
    return name

def get_keywords(name):
    """å°†æ–‡ä»¶ååˆ†å‰²ä¸ºå…³é”®è¯åˆ—è¡¨"""
    return name.strip().split()

def find_longest_common_keywords(keywords1, keywords2):
    """æ‰¾å‡ºä¸¤ä¸ªå…³é”®è¯åˆ—è¡¨ä¸­æœ€é•¿çš„è¿ç»­å…¬å…±éƒ¨åˆ†"""
    matcher = difflib.SequenceMatcher(None, keywords1, keywords2)
    match = matcher.find_longest_match(0, len(keywords1), 0, len(keywords2))
    return keywords1[match.a:match.a + match.size]

def validate_series_name(name):
    """éªŒè¯å’Œæ¸…ç†ç³»åˆ—åç§°
    
    Args:
        name: åŸå§‹ç³»åˆ—åç§°
        
    Returns:
        æ¸…ç†åçš„æœ‰æ•ˆç³»åˆ—åç§°ï¼Œå¦‚æœæ— æ•ˆåˆ™è¿”å›None
    """
    if not name or len(name) <= 1:
        return None
        
    # æ ‡å‡†åŒ–ä¸­æ–‡ï¼ˆè½¬æ¢ä¸ºç®€ä½“ï¼‰
    name = normalize_chinese(name)
    
    # å»é™¤æœ«å°¾çš„ç‰¹æ®Šå­—ç¬¦ã€æ•°å­—å’Œå•å­—
    name = re.sub(r'[\s.ï¼ã€‚Â·ãƒ»+ï¼‹\-ï¼â€”_ï¼¿\d]+$', '', name)  # å»é™¤æœ«å°¾çš„ç‰¹æ®Šç¬¦å·å’Œæ•°å­—
    name = re.sub(r'[ç¬¬ç« è¯é›†å·æœŸç¯‡å­£éƒ¨å†Œä¸Šä¸­ä¸‹å‰åå®Œå…¨][ç¯‡è¯é›†å·æœŸç« èŠ‚éƒ¨å†Œå…¨]*$', '', name)  # å»é™¤æœ«å°¾ç‰¹æ®Šè¯
    name = re.sub(r'(?i)vol\.?\s*\d*$', '', name)  # å»é™¤æœ«å°¾çš„vol.xxx
    name = re.sub(r'(?i)volume\s*\d*$', '', name)  # å»é™¤æœ«å°¾çš„volume xxx
    name = re.sub(r'(?i)part\s*\d*$', '', name)  # å»é™¤æœ«å°¾çš„part xxx
    name = name.strip()
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«comicå…³é”®è¯
    if re.search(r'(?i)comic', name):
        return None
    
    # æ£€æŸ¥æ˜¯å¦åªåŒ…å«3ä¸ªæˆ–æ›´å°‘çš„å•å­—æ¯
    words = name.split()
    if all(len(word) <= 1 for word in words) and len(''.join(words)) <= 3:
        return None
    
    # æœ€ç»ˆæ£€æŸ¥ï¼šç»“æœå¿…é¡»é•¿åº¦å¤§äº1ä¸”ä¸èƒ½ä»¥å•å­—ç»“å°¾
    if not name or len(name) <= 1 or (len(name) > 0 and len(name.split()[-1]) <= 1):
        return None
        
    return name

def find_series_groups(filenames, handler=None):
    """æŸ¥æ‰¾å±äºåŒä¸€ç³»åˆ—çš„æ–‡ä»¶ç»„ï¼Œä½¿ç”¨ä¸‰é˜¶æ®µåŒ¹é…ç­–ç•¥"""
    # é¢„å¤„ç†æ‰€æœ‰æ–‡ä»¶å
    processed_names = {f: preprocess_filename(f) for f in filenames}
    processed_keywords = {f: get_keywords(processed_names[f]) for f in filenames}
    # ä¸ºæ¯”è¾ƒåˆ›å»ºç®€ä½“ç‰ˆæœ¬
    simplified_names = {f: normalize_chinese(n) for f, n in processed_names.items()}
    simplified_keywords = {f: [normalize_chinese(k) for k in kws] for f, kws in processed_keywords.items()}
    
    # å­˜å‚¨ç³»åˆ—åˆ†ç»„
    series_groups = defaultdict(list)
    # å¾…å¤„ç†çš„æ–‡ä»¶é›†åˆ
    remaining_files = set(filenames)
    # è®°å½•å·²åŒ¹é…çš„æ–‡ä»¶
    matched_files = set()
    
    # é¢„å¤„ç†é˜¶æ®µï¼šæ£€æŸ¥å·²æ ‡è®°çš„ç³»åˆ—
    if handler:
        handler.update_panel("series_extract", "ğŸ” é¢„å¤„ç†é˜¶æ®µï¼šæ£€æŸ¥å·²æ ‡è®°çš„ç³»åˆ—")
    
    for file_path in list(remaining_files):
        if file_path in matched_files:
            continue
            
        file_name = os.path.basename(file_path)
        for prefix in SERIES_PREFIXES:
            if file_name.startswith(prefix):
                # æå–ç³»åˆ—å
                series_name = file_name[len(prefix):]
                # å»é™¤å¯èƒ½çš„å…¶ä»–æ ‡è®°
                series_name = re.sub(r'\[.*?\]|\(.*?\)', '', series_name)
                series_name = series_name.strip()
                if series_name:
                    series_groups[series_name].append(file_path)
                    matched_files.add(file_path)
                    remaining_files.remove(file_path)
                    if handler:
                        handler.update_panel("series_extract", f"âœ¨ é¢„å¤„ç†é˜¶æ®µï¼šæ–‡ä»¶ '{os.path.basename(file_path)}' å·²æ ‡è®°ä¸ºç³»åˆ— '{series_name}'")
                break
    
    # ç¬¬ä¸€é˜¶æ®µï¼šé£æ ¼åŒ¹é…ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰
    if handler:
        handler.update_panel("series_extract", "ğŸ” ç¬¬ä¸€é˜¶æ®µï¼šé£æ ¼åŒ¹é…ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰")
    
    while remaining_files:
        best_length = 0
        best_common = None
        best_pair = None
        best_series_name = None
        
        for file1 in remaining_files:
            if file1 in matched_files:
                continue
                
            keywords1 = simplified_keywords[file1]  # ä½¿ç”¨ç®€ä½“ç‰ˆæœ¬æ¯”è¾ƒ
            base_name1 = get_base_filename(os.path.basename(file1))  # è·å–åŸºç¡€å
            
            for file2 in remaining_files - {file1}:
                if file2 in matched_files:
                    continue
                    
                # æ£€æŸ¥åŸºç¡€åæ˜¯å¦å®Œå…¨ç›¸åŒ
                base_name2 = get_base_filename(os.path.basename(file2))
                if base_name1 == base_name2:
                    handler.update_panel("series_extract", f"âœ¨ ç¬¬ä¸€é˜¶æ®µï¼šæ–‡ä»¶ '{os.path.basename(file1)}' å’Œ '{os.path.basename(file2)}' åŸºç¡€åå®Œå…¨ç›¸åŒï¼Œè·³è¿‡")
                    continue  # å¦‚æœåŸºç¡€åå®Œå…¨ç›¸åŒ,è·³è¿‡è¿™å¯¹æ–‡ä»¶
                    
                keywords2 = simplified_keywords[file2]  # ä½¿ç”¨ç®€ä½“ç‰ˆæœ¬æ¯”è¾ƒ
                common = find_longest_common_keywords(keywords1, keywords2)
                # ä½¿ç”¨åŸå§‹å…³é”®è¯è·å–ç³»åˆ—å
                if common:
                    original_kw1 = processed_keywords[file1]
                    original_common = original_kw1[keywords1.index(common[0]):keywords1.index(common[-1])+1]
                    series_name = validate_series_name(' '.join(original_common))
                    if series_name and len(common) > best_length:
                        best_length = len(common)
                        best_common = common
                        best_pair = (file1, file2)
                        best_series_name = series_name
        
        if best_pair and best_series_name:
            matched_files_this_round = set(best_pair)
            base_name1 = get_base_filename(os.path.basename(best_pair[0]))
            
            for other_file in remaining_files - matched_files_this_round - matched_files:
                # æ£€æŸ¥åŸºç¡€åæ˜¯å¦ä¸ç¬¬ä¸€ä¸ªæ–‡ä»¶ç›¸åŒ
                other_base_name = get_base_filename(os.path.basename(other_file))
                if base_name1 == other_base_name:
                    continue  # å¦‚æœåŸºç¡€åç›¸åŒ,è·³è¿‡è¿™ä¸ªæ–‡ä»¶
                    
                other_keywords = simplified_keywords[other_file]  # ä½¿ç”¨ç®€ä½“ç‰ˆæœ¬æ¯”è¾ƒ
                common = find_longest_common_keywords(simplified_keywords[best_pair[0]], other_keywords)
                if common == best_common:
                    matched_files_this_round.add(other_file)
            
            # ä½¿ç”¨æœ€ä½³ç³»åˆ—å
            series_groups[best_series_name].extend(matched_files_this_round)
            remaining_files -= matched_files_this_round
            matched_files.update(matched_files_this_round)
            
            if handler:
                handler.update_panel("series_extract", f"âœ¨ ç¬¬ä¸€é˜¶æ®µï¼šé€šè¿‡å…³é”®è¯åŒ¹é…æ‰¾åˆ°ç³»åˆ— '{best_series_name}'")
                for file_path in matched_files_this_round:
                    handler.update_panel("series_extract", f"  â””â”€ æ–‡ä»¶ '{os.path.basename(file_path)}' åŒ¹é…åˆ°ç³»åˆ—ï¼ˆå…³é”®è¯ï¼š{' '.join(best_common)}ï¼‰")
        else:
            break  # æ²¡æœ‰æ‰¾åˆ°åŒ¹é…ï¼Œè¿›å…¥ç¬¬äºŒé˜¶æ®µ
    
    # ç¬¬äºŒé˜¶æ®µï¼šå®Œå…¨åŸºç¡€ååŒ¹é…
    if remaining_files:
        if handler:
            handler.update_panel("series_extract", "ğŸ” ç¬¬äºŒé˜¶æ®µï¼šå®Œå…¨åŸºç¡€ååŒ¹é…")
        
        # è·å–æ‰€æœ‰å·²å­˜åœ¨çš„ç³»åˆ—å
        existing_series = list(series_groups.keys())
        
        # ä»ç›®å½•ä¸­è·å–å·²æœ‰çš„ç³»åˆ—æ–‡ä»¶å¤¹åç§°
        dir_path = os.path.dirname(list(remaining_files)[0])  # è·å–ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„ç›®å½•è·¯å¾„
        try:
            for folder_name in os.listdir(dir_path):
                if os.path.isdir(os.path.join(dir_path, folder_name)):
                    # æ£€æŸ¥æ˜¯å¦æœ‰ç³»åˆ—æ ‡è®°
                    for prefix in SERIES_PREFIXES:
                        if folder_name.startswith(prefix):
                            series_name = folder_name[len(prefix):]  # å»æ‰å‰ç¼€
                            if series_name not in existing_series:
                                existing_series.append(series_name)
                                if handler:
                                    handler.update_panel("series_extract", f"ğŸ“ ç¬¬äºŒé˜¶æ®µï¼šä»ç›®å½•ä¸­æ‰¾åˆ°å·²æœ‰ç³»åˆ— '{series_name}'")
                            break
        except Exception:
            pass  # å¦‚æœè¯»å–ç›®å½•å¤±è´¥ï¼Œä»…ä½¿ç”¨å·²æœ‰çš„ç³»åˆ—å
        
        # æ£€æŸ¥å‰©ä½™æ–‡ä»¶æ˜¯å¦åŒ…å«å·²æœ‰ç³»åˆ—å
        matched_files_by_series = defaultdict(list)
        for file in list(remaining_files):
            if file in matched_files:
                continue
                
            base_name = simplified_names[file]  # ä½¿ç”¨ç®€ä½“ç‰ˆæœ¬æ¯”è¾ƒ
            base_name_no_space = re.sub(r'\s+', '', base_name)
            for series_name in existing_series:
                series_base = normalize_chinese(series_name)  # åªåœ¨æ¯”è¾ƒæ—¶è½¬æ¢ä¸ºç®€ä½“
                series_base_no_space = re.sub(r'\s+', '', series_base)
                # åªè¦æ–‡ä»¶åä¸­åŒ…å«ç³»åˆ—åå°±åŒ¹é…
                if series_base_no_space in base_name_no_space:
                    # æ£€æŸ¥æ˜¯å¦æœ‰åŸºç¡€åç›¸åŒçš„æ–‡ä»¶å·²ç»åœ¨è¿™ä¸ªç³»åˆ—ä¸­
                    base_name_current = get_base_filename(os.path.basename(file))
                    has_same_base = False
                    for existing_file in matched_files_by_series[series_name]:
                        if get_base_filename(os.path.basename(existing_file)) == base_name_current:
                            has_same_base = True
                            break
                    
                    if not has_same_base:
                        matched_files_by_series[series_name].append(file)  # ä½¿ç”¨åŸå§‹ç³»åˆ—å
                        matched_files.add(file)
                        remaining_files.remove(file)
                        if handler:
                            handler.update_panel("series_extract", f"âœ¨ ç¬¬äºŒé˜¶æ®µï¼šæ–‡ä»¶ '{os.path.basename(file)}' åŒ¹é…åˆ°å·²æœ‰ç³»åˆ— '{series_name}'ï¼ˆåŒ…å«ç³»åˆ—åï¼‰")
                    break
        
        # å°†åŒ¹é…çš„æ–‡ä»¶æ·»åŠ åˆ°å¯¹åº”çš„ç³»åˆ—ç»„
        for series_name, files in matched_files_by_series.items():
            series_groups[series_name].extend(files)
            if handler:
                handler.update_panel("series_extract", f"âœ¨ ç¬¬äºŒé˜¶æ®µï¼šå°† {len(files)} ä¸ªæ–‡ä»¶æ·»åŠ åˆ°ç³»åˆ— '{series_name}'")
                for file_path in files:
                    handler.update_panel("series_extract", f"  â””â”€ {os.path.basename(file_path)}")
    
    # ç¬¬ä¸‰é˜¶æ®µï¼šæœ€é•¿å…¬å…±å­ä¸²åŒ¹é…
    if remaining_files:
        if handler:
            handler.update_panel("series_extract", "ğŸ” ç¬¬ä¸‰é˜¶æ®µï¼šæœ€é•¿å…¬å…±å­ä¸²åŒ¹é…")
            
        while remaining_files:
            best_ratio = 0
            best_pair = None
            best_common = None
            original_form = None  # ä¿å­˜åŸå§‹å¤§å°å†™å½¢å¼
            
            # å¯¹å‰©ä½™æ–‡ä»¶è¿›è¡Œä¸¤ä¸¤æ¯”è¾ƒ
            for file1 in remaining_files:
                if file1 in matched_files:
                    continue
                    
                base1 = simplified_names[file1]  # ä½¿ç”¨ç®€ä½“ç‰ˆæœ¬æ¯”è¾ƒ
                base1_lower = base1.lower()
                original1 = processed_names[file1]  # ä¿å­˜åŸå§‹å½¢å¼
                base_name1 = get_base_filename(os.path.basename(file1))
                
                for file2 in remaining_files - {file1}:
                    if file2 in matched_files:
                        continue
                        
                    # æ£€æŸ¥åŸºç¡€åæ˜¯å¦å®Œå…¨ç›¸åŒ
                    base_name2 = get_base_filename(os.path.basename(file2))
                    if base_name1 == base_name2:
                        continue  # å¦‚æœåŸºç¡€åå®Œå…¨ç›¸åŒ,è·³è¿‡è¿™å¯¹æ–‡ä»¶
                        
                    base2 = simplified_names[file2]  # ä½¿ç”¨ç®€ä½“ç‰ˆæœ¬æ¯”è¾ƒ
                    base2_lower = base2.lower()
                    
                    # ä½¿ç”¨å°å†™å½¢å¼è¿›è¡Œæ¯”è¾ƒ
                    matcher = difflib.SequenceMatcher(None, base1_lower, base2_lower)
                    ratio = matcher.ratio()
                    if ratio > best_ratio and ratio > 0.6:
                        best_ratio = ratio
                        best_pair = (file1, file2)
                        match = matcher.find_longest_match(0, len(base1_lower), 0, len(base2_lower))
                        best_common = base1_lower[match.a:match.a + match.size]
                        # ä¿å­˜åŸå§‹å½¢å¼
                        original_form = original1[match.a:match.a + match.size]
            
            if best_pair and best_common and len(best_common.strip()) > 1:
                matched_files_this_round = set(best_pair)
                base_name1 = get_base_filename(os.path.basename(best_pair[0]))
                
                for other_file in remaining_files - matched_files_this_round - matched_files:
                    # æ£€æŸ¥åŸºç¡€åæ˜¯å¦ä¸ç¬¬ä¸€ä¸ªæ–‡ä»¶ç›¸åŒ
                    other_base_name = get_base_filename(os.path.basename(other_file))
                    if base_name1 == other_base_name:
                        continue  # å¦‚æœåŸºç¡€åç›¸åŒ,è·³è¿‡è¿™ä¸ªæ–‡ä»¶
                        
                    other_base = simplified_names[other_file].lower()  # ä½¿ç”¨ç®€ä½“å°å†™ç‰ˆæœ¬æ¯”è¾ƒ
                    if best_common in other_base:
                        matched_files_this_round.add(other_file)
                
                # ä½¿ç”¨åŸå§‹å½¢å¼ä½œä¸ºç³»åˆ—å
                series_name = validate_series_name(original_form)
                if series_name:
                    series_groups[series_name].extend(matched_files_this_round)
                    remaining_files -= matched_files_this_round
                    matched_files.update(matched_files_this_round)
                    if handler:
                        handler.update_panel("series_extract", f"âœ¨ ç¬¬ä¸‰é˜¶æ®µï¼šé€šè¿‡å…¬å…±å­ä¸²åŒ¹é…æ‰¾åˆ°ç³»åˆ— '{series_name}'")
                        handler.update_panel("series_extract", f"  â””â”€ å…¬å…±å­ä¸²ï¼š'{best_common}' (ç›¸ä¼¼åº¦: {best_ratio:.2%})")
                        for file_path in matched_files_this_round:
                            handler.update_panel("series_extract", f"  â””â”€ æ–‡ä»¶ '{os.path.basename(file_path)}'")
                else:
                    remaining_files.remove(best_pair[0])
                    matched_files.add(best_pair[0])
            else:
                break
    
    if handler and remaining_files:
        handler.update_panel("series_extract", f"âš ï¸ è¿˜æœ‰ {len(remaining_files)} ä¸ªæ–‡ä»¶æœªèƒ½åŒ¹é…åˆ°ä»»ä½•ç³»åˆ—")
        # for file_path in remaining_files:
        #     handler.update_panel("series_extract", f"  â””â”€ {os.path.basename(file_path)}")
    
    return dict(series_groups)

def create_series_folders(directory_path, archives, handler=None):
    """ä¸ºåŒä¸€ç³»åˆ—çš„æ–‡ä»¶åˆ›å»ºæ–‡ä»¶å¤¹"""
    dir_groups = defaultdict(list)
    # åªå¤„ç†å‹ç¼©åŒ…æ–‡ä»¶
    archives = [f for f in archives if os.path.isfile(f) and is_archive(f)]
    
    for archive in archives:
        dir_path = os.path.dirname(archive)
        # æ£€æŸ¥çˆ¶ç›®å½•æ˜¯å¦æœ‰ç³»åˆ—æ ‡è®°
        parent_name = os.path.basename(dir_path)
        is_series_dir = any(parent_name.startswith(prefix) for prefix in SERIES_PREFIXES)
        if is_series_dir:
            continue
        dir_groups[dir_path].append(archive)
    
    for dir_path, dir_archives in dir_groups.items():
        if len(dir_archives) <= 1:
            continue
            
        if handler:
            # æ›´æ–°å¤„ç†çŠ¶æ€
            handler.process_log_lines.clear()
            handler.process_log_lines.append(f"åˆ†æç›®å½•: {os.path.basename(dir_path)}")
            handler.update_panel("update_log", f"æ‰¾åˆ° {len(dir_archives)} ä¸ªå‹ç¼©åŒ…")
        
        series_groups = find_series_groups(dir_archives, handler)
        
        if series_groups:
            if handler:
                handler.update_panel("update_log", f"ğŸ“š æ‰¾åˆ° {len(series_groups)} ä¸ªç³»åˆ—")
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ–‡ä»¶éƒ½ä¼šè¢«ç§»åŠ¨åˆ°åŒä¸€ä¸ªç³»åˆ—
            total_files = len(dir_archives)
            for series_name, files in series_groups.items():
                if series_name == "å…¶ä»–":
                    continue
                if len(files) == total_files:
                    if handler:
                        handler.update_panel("update_log", f"âš ï¸ æ‰€æœ‰æ–‡ä»¶éƒ½å±äºåŒä¸€ä¸ªç³»åˆ—ï¼Œè·³è¿‡åˆ›å»ºå­æ–‡ä»¶å¤¹")
                    return
            
            # åˆ›å»ºä¸€ä¸ªå­—å…¸æ¥è®°å½•æ¯ä¸ªç³»åˆ—çš„æ–‡ä»¶å¤¹è·¯å¾„
            series_folders = {}
            
            # é¦–å…ˆåˆ›å»ºæ‰€æœ‰éœ€è¦çš„ç³»åˆ—æ–‡ä»¶å¤¹
            for series_name, files in series_groups.items():
                # è·³è¿‡"å…¶ä»–"åˆ†ç±»å’Œåªæœ‰ä¸€ä¸ªæ–‡ä»¶çš„ç³»åˆ—
                if series_name == "å…¶ä»–" or len(files) <= 1:
                    if handler:
                        if series_name == "å…¶ä»–":
                            handler.update_panel("update_log", f"âš ï¸ {len(files)} ä¸ªæ–‡ä»¶æœªèƒ½åŒ¹é…åˆ°ç³»åˆ—")
                        else:
                            handler.update_panel("update_log", f"âš ï¸ ç³»åˆ— '{series_name}' åªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œè·³è¿‡åˆ›å»ºæ–‡ä»¶å¤¹")
                    continue
                
                # æ·»åŠ ç³»åˆ—æ ‡è®°ï¼ˆä½¿ç”¨æ ‡å‡†ç³»åˆ—æ ‡è®°[#s]ï¼‰
                series_folder = os.path.join(dir_path, f'[#s]{series_name.strip()}')
                if not os.path.exists(series_folder):
                    os.makedirs(series_folder)
                    if handler:
                        handler.update_panel("update_log", f"ğŸ“ åˆ›å»ºç³»åˆ—æ–‡ä»¶å¤¹: [#s]{series_name}")
                series_folders[series_name] = series_folder
            
            # ç„¶åç§»åŠ¨æ¯ä¸ªç³»åˆ—çš„æ–‡ä»¶
            for series_name, folder_path in series_folders.items():
                files = series_groups[series_name]
                if handler:
                    handler.update_panel("update_log", f"ğŸ“¦ å¼€å§‹ç§»åŠ¨ç³»åˆ— '{series_name}' çš„æ–‡ä»¶...")
                
                for file_path in files:
                    # æ›´æ–°å¤„ç†çŠ¶æ€
                    if handler:
                        handler.process_log_lines.clear()
                        handler.process_log_lines.append(f"ç§»åŠ¨: {os.path.basename(file_path)}")
                    
                    target_path = os.path.join(folder_path, os.path.basename(file_path))
                    if not os.path.exists(target_path):
                        shutil.move(file_path, target_path)
                        if handler:
                            handler.update_panel("update_log", f"  â””â”€ ç§»åŠ¨: {os.path.basename(file_path)}")
                    else:
                        if handler:
                            handler.update_panel("update_log", f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨äºç³»åˆ— '{series_name}': {os.path.basename(file_path)}")
            
            if handler:
                handler.update_panel("current_task", "ç³»åˆ—æå–å®Œæˆ")
        
        if handler:
            handler.update_panel("folder_process", f"âœ¨ ç›®å½•å¤„ç†å®Œæˆ: {dir_path}")

# æ–°å¢çš„è¾…åŠ©å‡½æ•°
def validate_directory(directory_path, handler=None):
    """éªŒè¯ç›®å½•æ˜¯å¦æœ‰æ•ˆä¸”ä¸åœ¨é»‘åå•ä¸­"""
    abs_dir_path = os.path.abspath(directory_path)
    if not os.path.isdir(abs_dir_path):
        if handler:
            handler.update_panel("update_log", f"âŒ ä¸æ˜¯æœ‰æ•ˆçš„ç›®å½•è·¯å¾„: {abs_dir_path}")
        return None
    
    if is_path_blacklisted(abs_dir_path):
        if handler:
            handler.update_panel("update_log", f"âš ï¸ ç›®å½•åœ¨é»‘åå•ä¸­ï¼Œè·³è¿‡å¤„ç†: {abs_dir_path}")
        return None
        
    return abs_dir_path

def collect_archives_for_category(directory_path, category_folders, handler=None):
    """æ”¶é›†ç”¨äºåˆ†ç±»çš„å‹ç¼©åŒ…"""
    archives = []
    archives_to_check = []
    
    with os.scandir(directory_path) as entries:
        for entry in entries:
            if entry.is_file() and is_archive(entry.name):
                parent_dir = os.path.basename(os.path.dirname(entry.path))
                # è·³è¿‡æŸåå‹ç¼©åŒ…æ–‡ä»¶å¤¹å’Œåˆ†ç±»æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶
                if parent_dir == "æŸåå‹ç¼©åŒ…" or parent_dir in category_folders:
                    continue
                archives_to_check.append(entry.path)
    
    if archives_to_check:
        if handler:
            handler.update_panel("update_log", f"ğŸ” æ­£åœ¨æ£€æŸ¥ {len(archives_to_check)} ä¸ªå‹ç¼©åŒ…çš„å®Œæ•´æ€§...")
        
        # ä½¿ç”¨çº¿ç¨‹æ± æ£€æŸ¥å‹ç¼©åŒ…
        with ThreadPoolExecutor(max_workers=16) as executor:
            futures = {executor.submit(is_archive_corrupted, path): path for path in archives_to_check}
            for i, future in enumerate(futures, 1):
                path = futures[future]
                if handler:
                    # æ›´æ–°å½“å‰ä»»åŠ¡çŠ¶æ€
                    percentage = i / len(archives_to_check) * 100
                    handler.update_panel("current_task", f"æ£€æµ‹å‹ç¼©åŒ…å®Œæ•´æ€§... ({i}/{len(archives_to_check)}) {percentage:.1f}%")
                try:
                    is_corrupted = future.result()
                    if not is_corrupted:
                        archives.append(path)
                    elif handler:
                        handler.update_panel("update_log", f"âš ï¸ å‹ç¼©åŒ…å·²æŸåï¼Œè·³è¿‡: {os.path.basename(path)}")
                except TimeoutError:
                    if handler:
                        handler.update_panel("update_log", f"âš ï¸ å‹ç¼©åŒ…å¤„ç†è¶…æ—¶ï¼Œè·³è¿‡: {os.path.basename(path)}")
                except Exception as e:
                    if handler:
                        handler.update_panel("update_log", f"âŒ æ£€æŸ¥å‹ç¼©åŒ…æ—¶å‡ºé”™: {os.path.basename(path)}")
    
    return archives

def collect_archives_for_series(directory_path, category_folders, handler=None):
    """æ”¶é›†ç”¨äºç³»åˆ—æå–çš„å‹ç¼©åŒ…"""
    base_level = len(Path(directory_path).parts)
    archives = []
    archives_to_check = []
    
    for root, _, files in os.walk(directory_path):
        current_level = len(Path(root).parts)
        if current_level - base_level > 1:
            continue
            
        if is_path_blacklisted(root):
            if handler:
                handler.update_panel("update_log", f"âš ï¸ ç›®å½•åœ¨é»‘åå•ä¸­ï¼Œè·³è¿‡: {root}")
            continue
            
        # æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦æœ‰ç³»åˆ—æ ‡è®°æˆ–æ˜¯æŸåå‹ç¼©åŒ…æ–‡ä»¶å¤¹
        current_dir = os.path.basename(root)
        if current_dir.startswith('[#s]') or current_dir == "æŸåå‹ç¼©åŒ…":
            continue
            
        for file in files:
            if is_archive(file):
                file_path = os.path.join(root, file)
                # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åœ¨ç³»åˆ—æå–é»‘åå•ä¸­
                if is_series_blacklisted(file):
                    if handler:
                        handler.update_panel("update_log", f"âš ï¸ æ–‡ä»¶åœ¨ç³»åˆ—æå–é»‘åå•ä¸­ï¼Œè·³è¿‡: {file}")
                    continue
                if is_path_blacklisted(file):
                    if handler:
                        handler.update_panel("update_log", f"âš ï¸ æ–‡ä»¶åœ¨é»‘åå•ä¸­ï¼Œè·³è¿‡: {file}")
                    continue
                archives_to_check.append(file_path)
    
    if archives_to_check:
        if handler:
            handler.update_panel("update_log", f"ğŸ” æ­£åœ¨æ£€æŸ¥ {len(archives_to_check)} ä¸ªå‹ç¼©åŒ…çš„å®Œæ•´æ€§...")
        
        # ä½¿ç”¨çº¿ç¨‹æ± æ£€æŸ¥å‹ç¼©åŒ…
        with ThreadPoolExecutor(max_workers=16) as executor:
            futures = {executor.submit(is_archive_corrupted, path): path for path in archives_to_check}
            for i, future in enumerate(futures, 1):
                path = futures[future]
                if handler:
                    # æ›´æ–°å½“å‰ä»»åŠ¡çŠ¶æ€
                    percentage = i / len(archives_to_check) * 100
                    handler.update_panel("current_task", f"æ£€æµ‹å‹ç¼©åŒ…å®Œæ•´æ€§... ({i}/{len(archives_to_check)}) {percentage:.1f}%")
                try:
                    is_corrupted = future.result()
                    if is_corrupted:
                        if handler:
                            handler.update_panel("update_log", f"âš ï¸ å‹ç¼©åŒ…å·²æŸå: {os.path.basename(path)}")
                        # ç§»åŠ¨æŸåçš„å‹ç¼©åŒ…
                        move_corrupted_archive(path, directory_path, handler)
                    else:
                        archives.append(path)
                except TimeoutError:
                    if handler:
                        handler.update_panel("update_log", f"âš ï¸ å‹ç¼©åŒ…å¤„ç†è¶…æ—¶: {os.path.basename(path)}")
                    # å°†è¶…æ—¶çš„å‹ç¼©åŒ…ä¹Ÿè§†ä¸ºæŸå
                    move_corrupted_archive(path, directory_path, handler)
                except Exception as e:
                    if handler:
                        handler.update_panel("update_log", f"âŒ æ£€æŸ¥å‹ç¼©åŒ…æ—¶å‡ºé”™: {os.path.basename(path)}")
                    # å°†å‡ºé”™çš„å‹ç¼©åŒ…ä¹Ÿè§†ä¸ºæŸå
                    move_corrupted_archive(path, directory_path, handler)
                    
    return archives

def run_post_processing(directory_path, enabled_features, handler=None):
    """è¿è¡Œåç»­å¤„ç†è„šæœ¬ï¼ˆåˆ é™¤ç©ºæ–‡ä»¶å¤¹å’Œåºå·ä¿®å¤ï¼‰"""
    if 3 in enabled_features:
        try:
            handler.update_panel("post_process", "ğŸ—‘ï¸ æ­£åœ¨åˆ é™¤ç©ºæ–‡ä»¶å¤¹...")
            # è¿è¡Œå­è¿›ç¨‹
            result = subprocess.run(
                f'python "D:\\1VSCODE\\1ehv\\archive\\013-åˆ é™¤ç©ºæ–‡ä»¶å¤¹é‡Šæ”¾å•ç‹¬æ–‡ä»¶å¤¹.py" "{directory_path}" -r', 
                shell=True,
                capture_output=True,
                text=True,
                encoding='utf-8'
            )
            
            if result.returncode != 0:
                raise subprocess.CalledProcessError(result.returncode, result.args)
            
            handler.update_panel("post_process", "âœ… ç©ºæ–‡ä»¶å¤¹å¤„ç†å®Œæˆ")
                
        except subprocess.CalledProcessError as e:
            if handler:
                handler.update_panel("update_log", f"âŒ è¿è¡Œåˆ é™¤ç©ºæ–‡ä»¶å¤¹è„šæœ¬å¤±è´¥: {str(e)}")
                handler.update_panel("post_process", "âŒ ç©ºæ–‡ä»¶å¤¹å¤„ç†å¤±è´¥")
    
    if 4 in enabled_features:
        try:
            handler.update_panel("post_process", "ğŸ”§ æ­£åœ¨ä¿®å¤åºå·...")
            # è¿è¡Œå­è¿›ç¨‹
            result = subprocess.run(
                f'python "D:\\1VSCODE\\1ehv\\other\\012-æ–‡ä»¶å¤¹åºå·ä¿®å¤å·¥å…·.py" "{directory_path}"', 
                shell=True,
                capture_output=True,
                text=True,
                encoding='utf-8'
            )
            
            if result.returncode != 0:
                raise subprocess.CalledProcessError(result.returncode, result.args)
            
            handler.update_panel("post_process", "âœ… åºå·ä¿®å¤å®Œæˆ")
                
        except subprocess.CalledProcessError as e:
            if handler:
                handler.update_panel("update_log", f"âŒ è¿è¡Œåºå·ä¿®å¤è„šæœ¬å¤±è´¥: {str(e)}")
                handler.update_panel("post_process", "âŒ åºå·ä¿®å¤å¤±è´¥")

def process_directory(directory_path, progress_task=None, enabled_features=None, handler=None):
    """å¤„ç†ç›®å½•ä¸‹çš„å‹ç¼©åŒ…"""
    try:
        if enabled_features is None:
            enabled_features = {1, 2, 3, 4}
            
        # éªŒè¯ç›®å½•
        abs_dir_path = validate_directory(directory_path)
        if not abs_dir_path:
            return []

        # å¦‚æœæ²¡æœ‰ä¼ å…¥ handlerï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
        handler_created = False
        if handler is None:
            handler = get_handler()
            handler_created = True

        try:
            # æ›´æ–°æ–‡ä»¶å¤¹å¤„ç†çŠ¶æ€
            handler.update_panel("folder_process", f"ğŸ“‚ å¼€å§‹å¤„ç†ç›®å½•: {abs_dir_path}")
            
            # æ›´æ–°æ—§çš„ç³»åˆ—æ–‡ä»¶å¤¹åç§°
            if 2 in enabled_features:
                handler.update_panel("folder_process", "ğŸ”„ æ£€æŸ¥å¹¶æ›´æ–°æ—§çš„ç³»åˆ—æ–‡ä»¶å¤¹åç§°...")
                update_all_series_folders(abs_dir_path, handler)
            
            # åˆ›å»ºåˆ†ç±»æ–‡ä»¶å¤¹ï¼ˆåŠŸèƒ½1ï¼‰
            if 1 in enabled_features:
                create_category_folders(abs_dir_path)
            
            category_folders = set(CATEGORY_RULES.keys())
            found_archives = False
            
            # åŠŸèƒ½2ï¼ˆç³»åˆ—æå–ï¼‰
            if 2 in enabled_features:
                handler.update_panel("folder_process", "ğŸ” å¼€å§‹æŸ¥æ‰¾å¯æå–ç³»åˆ—çš„å‹ç¼©åŒ…...")
                archives = collect_archives_for_series(abs_dir_path, category_folders, handler)
                if archives:
                    found_archives = True
                    total_archives = len(archives)
                    handler.set_total(total_archives)
                    handler.update_panel("update_log", f"âœ¨ åœ¨ç›®å½• '{abs_dir_path}' åŠå…¶å­æ–‡ä»¶å¤¹ä¸‹æ‰¾åˆ° {total_archives} ä¸ªæœ‰æ•ˆå‹ç¼©åŒ…")
                    
                    # ç›´æ¥å¤„ç†æ‰€æœ‰å‹ç¼©åŒ…
                    create_series_folders(abs_dir_path, archives, handler)
                    
                    # æ›´æ–°è¿›åº¦
                    handler.update_panel("current_task", "ç³»åˆ—æå–å®Œæˆ")
                else:
                    handler.update_panel("folder_process", "æ²¡æœ‰æ‰¾åˆ°å¯æå–ç³»åˆ—çš„å‹ç¼©åŒ…")
            
            # åŠŸèƒ½1ï¼ˆåˆ†ç±»ï¼‰
            if 1 in enabled_features:
                handler.update_panel("folder_process", "ğŸ” å¼€å§‹æŸ¥æ‰¾éœ€è¦åˆ†ç±»çš„å‹ç¼©åŒ…...")
                archives = collect_archives_for_category(abs_dir_path, category_folders, handler)
                if archives:
                    found_archives = True
                    total_archives = len(archives)
                    handler.set_total(total_archives)
                    handler.update_panel("update_log", f"âœ¨ åœ¨ç›®å½• '{abs_dir_path}' ä¸‹æ‰¾åˆ° {total_archives} ä¸ªæœ‰æ•ˆå‹ç¼©åŒ…")
                    
                    # æ„å»ºè¿›åº¦æ¡
                    for i, archive in enumerate(archives, 1):
                        percentage = i / total_archives * 100
                        bar_width = 50
                        completed_width = int(bar_width * percentage / 100)
                        progress_bar = f"[{'=' * completed_width}{' ' * (bar_width - completed_width)}]"
                        progress_text = f"æ­£åœ¨åˆ†ç±»å‹ç¼©åŒ…... {progress_bar} {percentage:.1f}% ({i}/{total_archives})"
                        handler.update_panel("current_task", progress_text)
                        
                        # æ›´æ–°å¤„ç†çŠ¶æ€
                        handler.update_panel("archive_process", f"å¤„ç†: {os.path.basename(archive)}")
                        process_single_file(archive, handler)
                else:
                    handler.update_panel("folder_process", "æ²¡æœ‰æ‰¾åˆ°éœ€è¦åˆ†ç±»çš„å‹ç¼©åŒ…")
            
            # è¿è¡Œåç»­å¤„ç†
            if 3 in enabled_features or 4 in enabled_features:
                handler.update_panel("post_process", "ğŸ”§ å¼€å§‹è¿è¡Œåç»­å¤„ç†...")
                # run_post_processing(abs_dir_path, enabled_features, handler)
            
            if not found_archives:
                handler.update_panel("folder_process", f"åœ¨ç›®å½• '{abs_dir_path}' ä¸‹æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„å‹ç¼©åŒ…")
            
            handler.update_panel("folder_process", f"âœ¨ ç›®å½•å¤„ç†å®Œæˆ: {abs_dir_path}")
            
        finally:
            # å¦‚æœæ˜¯æˆ‘ä»¬åˆ›å»ºçš„ handlerï¼Œéœ€è¦å…³é—­å®ƒ
            if handler_created:
                close_handler()
        
        return []
            
    except Exception as e:
        if handler:
            handler.update_panel("update_log", f"âŒ å¤„ç†ç›®å½•æ—¶å‡ºé”™ {directory_path}: {str(e)}")
            handler.update_panel("folder_process", f"âŒ å¤„ç†å‡ºé”™: {os.path.basename(directory_path)}")
        return []

def process_paths(paths, enabled_features=None, similarity_config=None, wait_for_confirm=False):
    """å¤„ç†è¾“å…¥çš„è·¯å¾„åˆ—è¡¨"""
    if similarity_config:
        SIMILARITY_CONFIG.update(similarity_config)
        
    valid_paths = []
    for path in paths:
        path = path.strip().strip('"').strip("'")
        if path:
            try:
                if sys.platform == 'win32':
                    if win32_path_exists(path):
                        valid_paths.append(path)
                    else:
                        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {path}")
                else:
                    if os.path.exists(path):
                        valid_paths.append(path)
                    else:
                        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {path}")
            except Exception as e:
                print(f"âŒ å¤„ç†è·¯å¾„æ—¶å‡ºé”™: {path}, é”™è¯¯: {str(e)}")
    
    if not valid_paths:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„è·¯å¾„")
        return
    
    total_paths = len(valid_paths)
    print(f"\nğŸš€ å¼€å§‹{'å¤„ç†' if wait_for_confirm else 'æ‰¹é‡å¤„ç†'} {total_paths} ä¸ªè·¯å¾„...")
    if not wait_for_confirm:
        print("è·¯å¾„åˆ—è¡¨:")
        for path in valid_paths:
            print(f"  - {path}")
        print()
    
    # åªæœ‰åœ¨å¼€å§‹å®é™…å¤„ç†æ—¶æ‰åˆ›å»º handler
    with get_handler() as handler:
        for i, path in enumerate(valid_paths, 1):
            try:
                if wait_for_confirm:
                    handler.update_panel("current_task", f"ğŸ“ å¤„ç†ç¬¬ {i}/{total_paths} ä¸ªè·¯å¾„: {path}")
                else:
                    handler.update_panel("current_task", f"å¤„ç†: {os.path.basename(path)}")
                    
                if sys.platform == 'win32':
                    if win32_path_exists(path):
                        if os.path.isdir(path):
                            process_directory(path, enabled_features=enabled_features, handler=handler)
                        elif os.path.isfile(path) and is_archive(path):
                            if 1 in enabled_features:
                                if wait_for_confirm:
                                    handler.update_panel("current_task", f"ğŸ“¦ å¤„ç†å•ä¸ªæ–‡ä»¶: {path}")
                                process_single_file(path, handler)
                                if wait_for_confirm:
                                    handler.update_panel("update_log", "âœ¨ æ–‡ä»¶å¤„ç†å®Œæˆ")
                else:
                    if os.path.isdir(path):
                        process_directory(path, enabled_features=enabled_features, handler=handler)
                    elif os.path.isfile(path) and is_archive(path):
                        if 1 in enabled_features:
                            if wait_for_confirm:
                                handler.update_panel("current_task", f"ğŸ“¦ å¤„ç†å•ä¸ªæ–‡ä»¶: {path}")
                            process_single_file(path, handler)
                            if wait_for_confirm:
                                handler.update_panel("update_log", "âœ¨ æ–‡ä»¶å¤„ç†å®Œæˆ")
                
                if wait_for_confirm and i < total_paths:
                    handler.update_panel("current_task", f"â¸ï¸ å·²å¤„ç†å®Œç¬¬ {i}/{total_paths} ä¸ªè·¯å¾„")
                    input("æŒ‰å›è½¦é”®ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªè·¯å¾„...")
                    
            except Exception as e:
                handler.update_panel("update_log", f"âŒ å¤„ç†è·¯å¾„æ—¶å‡ºé”™: {path}, é”™è¯¯: {str(e)}")
                if wait_for_confirm and i < total_paths:
                    handler.update_panel("update_log", f"âš ï¸ å¤„ç†å‡ºé”™ï¼Œæ˜¯å¦ç»§ç»­ï¼Ÿ")
                    input("æŒ‰å›è½¦é”®ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªè·¯å¾„ï¼ŒæŒ‰ Ctrl+C ç»ˆæ­¢ç¨‹åº...")
        
        if wait_for_confirm:
            handler.update_panel("update_log", "âœ… æ‰€æœ‰è·¯å¾„å¤„ç†å®Œæˆï¼")
        else:
            handler.update_panel("update_log", f"âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼å…±å¤„ç† {total_paths} ä¸ªè·¯å¾„")

def process_args():
    """å¤„ç†å‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='æ¼«ç”»å‹ç¼©åŒ…åˆ†ç±»å·¥å…·')
    parser.add_argument('paths', nargs='*', help='è¦å¤„ç†çš„è·¯å¾„åˆ—è¡¨')
    parser.add_argument('-c', '--clipboard', action='store_true', help='ä»å‰ªè´´æ¿è¯»å–è·¯å¾„')
    parser.add_argument('-f', '--features', type=str, default='',
                      help='å¯ç”¨çš„åŠŸèƒ½ï¼ˆ1-4ï¼Œç”¨é€—å·åˆ†éš”ï¼‰ï¼š1=åˆ†ç±»ï¼Œ2=ç³»åˆ—æå–ï¼Œ3=åˆ é™¤ç©ºæ–‡ä»¶å¤¹ï¼Œ4=åºå·ä¿®å¤ã€‚é»˜è®¤å…¨éƒ¨å¯ç”¨')
    parser.add_argument('--similarity', type=float, default=80,
                      help='è®¾ç½®åŸºæœ¬ç›¸ä¼¼åº¦é˜ˆå€¼(0-100)ï¼Œé»˜è®¤80')
    parser.add_argument('--ratio', type=float, default=75,
                      help='è®¾ç½®å®Œå…¨åŒ¹é…é˜ˆå€¼(0-100)ï¼Œé»˜è®¤75')
    parser.add_argument('--partial', type=float, default=85,
                      help='è®¾ç½®éƒ¨åˆ†åŒ¹é…é˜ˆå€¼(0-100)ï¼Œé»˜è®¤85')
    parser.add_argument('--token', type=float, default=80,
                      help='è®¾ç½®æ ‡è®°åŒ¹é…é˜ˆå€¼(0-100)ï¼Œé»˜è®¤80')
    parser.add_argument('--length-diff', type=float, default=0.3,
                      help='è®¾ç½®é•¿åº¦å·®å¼‚æœ€å¤§å€¼(0-1)ï¼Œé»˜è®¤0.3')
    parser.add_argument('--wait', action='store_true', help='å¤„ç†å®Œæ¯ä¸ªè·¯å¾„åç­‰å¾…ç”¨æˆ·ç¡®è®¤')

    # å¦‚æœæ²¡æœ‰å‚æ•°æˆ–åªæœ‰-cå‚æ•°ï¼Œä½¿ç”¨TUI
    if len(sys.argv) == 1 or (len(sys.argv) == 2 and sys.argv[1] in ['-c', '--clipboard']):
        # é¢„è®¾é…ç½®
        presets = {
            "é»˜è®¤é…ç½®": {
                "features": "1,2,3,4",
                "similarity": "80",
                "ratio": "75",
                "partial": "85",
                "token": "80",
                "length_diff": "0.3",
                "clipboard": True,
                "wait": False
            },
            "ä»…åˆ†ç±»": {
                "features": "1",
                "similarity": "80",
                "ratio": "75",
                "partial": "85",
                "token": "80",
                "length_diff": "0.3",
                "clipboard": True,
                "wait": False
            },
            "ä»…ç³»åˆ—æå–": {
                "features": "2",
                "similarity": "80",
                "ratio": "75",
                "partial": "85",
                "token": "80",
                "length_diff": "0.3",
                "clipboard": True,
                "wait": False
            },
            "åˆ†ç±»+ç³»åˆ—": {
                "features": "1,2",
                "similarity": "80",
                "ratio": "75",
                "partial": "85",
                "token": "80",
                "length_diff": "0.3",
                "clipboard": True,
                "wait": False
            }
        }

        # åˆ›å»ºTUIé…ç½®ç•Œé¢
        checkbox_options = [
            ("ä»å‰ªè´´æ¿è¯»å–", "clipboard", "-c", True),
            ("åˆ†ç±»åŠŸèƒ½", "feature1", "-f 1"),
            ("ç³»åˆ—æå–", "feature2", "-f 2"),
            ("åˆ é™¤ç©ºæ–‡ä»¶å¤¹", "feature3", "-f 3"),
            ("åºå·ä¿®å¤", "feature4", "-f 4"),
            ("ç­‰å¾…ç¡®è®¤", "wait", "--wait", False),
        ]

        input_options = [
            ("åŸºæœ¬ç›¸ä¼¼åº¦é˜ˆå€¼", "similarity", "--similarity", "80", "0-100"),
            ("å®Œå…¨åŒ¹é…é˜ˆå€¼", "ratio", "--ratio", "75", "0-100"),
            ("éƒ¨åˆ†åŒ¹é…é˜ˆå€¼", "partial", "--partial", "85", "0-100"),
            ("æ ‡è®°åŒ¹é…é˜ˆå€¼", "token", "--token", "80", "0-100"),
            ("é•¿åº¦å·®å¼‚æœ€å¤§å€¼", "length_diff", "--length-diff", "0.3", "0-1"),
        ]

        app = create_config_app(
            program=__file__,
            checkbox_options=checkbox_options,
            input_options=input_options,
            title="æ¼«ç”»å‹ç¼©åŒ…åˆ†ç±»å·¥å…·é…ç½®",
            preset_configs=presets
        )
        app.run()
        return None, None

    args = parser.parse_args()
    
    # å¦‚æœä½¿ç”¨äº† -c å‚æ•°ï¼Œä»å‰ªè´´æ¿è¯»å–è·¯å¾„
    if args.clipboard:
        try:
            import pyperclip
            clipboard_content = pyperclip.paste().strip()
            if clipboard_content:
                args.paths.extend([p.strip() for p in clipboard_content.replace('\r\n', '\n').split('\n') if p.strip()])
                print("ä»å‰ªè´´æ¿è¯»å–åˆ°ä»¥ä¸‹è·¯å¾„ï¼š")
                for path in args.paths:
                    print(path)
        except ImportError:
            print("æœªå®‰è£… pyperclip æ¨¡å—ï¼Œæ— æ³•ä»å‰ªè´´æ¿è¯»å–è·¯å¾„")

    return args.paths, args

def run_classifier(paths, args):
    """è¿è¡Œåˆ†ç±»å™¨ä¸»é€»è¾‘"""
    if not paths or not args:
        return

    # æ›´æ–°ç›¸ä¼¼åº¦é…ç½®
    similarity_config = {
        'THRESHOLD': args.similarity,
        'RATIO_THRESHOLD': args.ratio,
        'PARTIAL_THRESHOLD': args.partial,
        'TOKEN_THRESHOLD': args.token,
        'LENGTH_DIFF_MAX': args.length_diff
    }
    SIMILARITY_CONFIG.update(similarity_config)

    # è§£æå¯ç”¨çš„åŠŸèƒ½
    enabled_features = set()
    if args.features:
        try:
            enabled_features = {int(f.strip()) for f in args.features.split(',') if f.strip()}
            for f in enabled_features.copy():
                if f not in {1, 2, 3, 4}:
                    print(f"æ— æ•ˆçš„åŠŸèƒ½ç¼–å·: {f}")
                    enabled_features.remove(f)
        except ValueError:
            print("æ— æ•ˆçš„åŠŸèƒ½ç¼–å·æ ¼å¼ï¼Œå°†å¯ç”¨æ‰€æœ‰åŠŸèƒ½")
            enabled_features = {1, 2, 3, 4}
    else:
        enabled_features = {1, 2, 3, 4}

    # å¤„ç†è·¯å¾„
    process_paths(paths, enabled_features=enabled_features, wait_for_confirm=args.wait)

def main():
    # è®¾ç½®æ§åˆ¶å°ç¼–ç ä¸ºUTF-8
    if sys.platform == 'win32':
        try:
            import ctypes
            kernel32 = ctypes.windll.kernel32
            kernel32.SetConsoleCP(65001)
            kernel32.SetConsoleOutputCP(65001)
        except:
            print("æ— æ³•è®¾ç½®æ§åˆ¶å°ç¼–ç ä¸ºUTF-8")

    paths, args = process_args()
    run_classifier(paths, args)

if __name__ == "__main__":
    main()