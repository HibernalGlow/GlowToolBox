import os
import subprocess
import json  # å°†yamlæ”¹ä¸ºjson
from datetime import datetime
import concurrent.futures
from functools import partial
import shutil
import argparse
import pyperclip
from pathlib import Path
import sys
import logging
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from nodes.tui.textual_logger import TextualLoggerManager
from nodes.record.logger_config import setup_logger

# è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
# å°†å†å²æ–‡ä»¶ä»yamlæ”¹ä¸ºjson
HISTORY_FILE = os.path.join(SCRIPT_DIR, 'archive_check_history.json')

# é…ç½®æ—¥å¿—é¢æ¿å¸ƒå±€
TEXTUAL_LAYOUT = {
    "status": {
        "ratio": 2,
        "title": "ğŸ“Š çŠ¶æ€ä¿¡æ¯",
        "style": "lightblue"
    },
    "progress": {
        "ratio": 2,
        "title": "ğŸ”„ å¤„ç†è¿›åº¦",
        "style": "lightcyan"
    },
    "success": {
        "ratio": 3,
        "title": "âœ… æˆåŠŸä¿¡æ¯",
        "style": "lightgreen"
    },
    "warning": {
        "ratio": 2,
        "title": "âš ï¸ è­¦å‘Šä¿¡æ¯",
        "style": "lightyellow"
    },
    "error": {
        "ratio": 2,
        "title": "âŒ é”™è¯¯ä¿¡æ¯",
        "style": "lightred"
    }
}

# åˆå§‹åŒ–æ—¥å¿—
config = {
    'script_name': 'bad_zip_tdel',
    'console_enabled': False
}
logger, config_info = setup_logger(config)

def load_check_history():
    """åŠ è½½æ£€æµ‹å†å²è®°å½•ï¼ˆä»JSONæ–‡ä»¶ï¼‰"""
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f) or {}
        except json.JSONDecodeError:
            logger.error(f"[#error] å†å²è®°å½•æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œå°†åˆ›å»ºæ–°çš„å†å²è®°å½•")
            return {}
    return {}

def save_check_history(history):
    """ä¿å­˜æ£€æµ‹å†å²è®°å½•ï¼ˆåˆ°JSONæ–‡ä»¶ï¼‰"""
    with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(history, f, indent=2, ensure_ascii=False)

def check_archive(file_path):
    """æ£€æµ‹å‹ç¼©åŒ…æ˜¯å¦æŸå"""
    try:
        result = subprocess.run(['7z', 't', file_path], 
                              capture_output=True, 
                              text=True)
        return result.returncode == 0
    except Exception as e:
        logger.error(f"[#error] âŒ æ£€æµ‹æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return False

def get_archive_files(directory, archive_extensions):
    """å¿«é€Ÿæ”¶é›†éœ€è¦å¤„ç†çš„æ–‡ä»¶"""
    for root, _, files in os.walk(directory):
        for filename in files:
            if any(filename.lower().endswith(ext) for ext in archive_extensions):
                yield os.path.join(root, filename)

def get_paths_from_clipboard():
    """ä»å‰ªè´´æ¿è¯»å–å¤šè¡Œè·¯å¾„"""
    try:
        clipboard_content = pyperclip.paste()
        if not clipboard_content:
            return []
            
        paths = [
            Path(path.strip().strip('"').strip("'"))
            for path in clipboard_content.splitlines() 
            if path.strip()
        ]
        
        valid_paths = [
            path for path in paths 
            if path.exists()
        ]
        
        if valid_paths:
            logger.info(f"[#status] ğŸ“‹ ä»å‰ªè´´æ¿è¯»å–åˆ° {len(valid_paths)} ä¸ªæœ‰æ•ˆè·¯å¾„")
        else:
            logger.warning("[#warning] âš ï¸ å‰ªè´´æ¿ä¸­æ²¡æœ‰æœ‰æ•ˆè·¯å¾„")
            
        return valid_paths
        
    except Exception as e:
        logger.error(f"[#error] âŒ è¯»å–å‰ªè´´æ¿æ—¶å‡ºé”™: {e}")
        return []

def process_directory(directory, skip_checked=False, max_workers=4):
    """å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰å‹ç¼©åŒ…æ–‡ä»¶"""
    archive_extensions = ('.zip', '.rar', '.7z', '.cbz')
    check_history = load_check_history()
    
    # åˆ é™¤temp_å¼€å¤´çš„æ–‡ä»¶å¤¹
    for root, dirs, _ in os.walk(directory, topdown=True):
        for dir_name in dirs[:]:  # ä½¿ç”¨åˆ‡ç‰‡åˆ›å»ºå‰¯æœ¬ä»¥é¿å…åœ¨è¿­ä»£æ—¶ä¿®æ”¹åˆ—è¡¨
            if dir_name.startswith('temp_'):
                try:
                    dir_path = os.path.join(root, dir_name)
                    logger.info(f"[#status] ğŸ—‘ï¸ æ­£åœ¨åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤¹: {dir_path}")
                    shutil.rmtree(dir_path)
                except Exception as e:
                    logger.error(f"[#error] åˆ é™¤æ–‡ä»¶å¤¹ {dir_path} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

    # æ”¶é›†éœ€è¦å¤„ç†çš„æ–‡ä»¶
    files_to_process = []
    for root, _, files in os.walk(directory):
        for filename in files:
            if filename.lower().endswith(archive_extensions):
                file_path = os.path.join(root, filename)
                if file_path.endswith('.tdel'):
                    continue
                if skip_checked and file_path in check_history and check_history[file_path]['valid']:
                    logger.info(f"[#status] â­ï¸ è·³è¿‡å·²æ£€æŸ¥ä¸”å®Œå¥½çš„æ–‡ä»¶: {file_path}")
                    continue
                files_to_process.append(file_path)

    if not files_to_process:
        logger.info("[#status] âœ¨ æ²¡æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶")
        return

    # æ›´æ–°è¿›åº¦ä¿¡æ¯
    total_files = len(files_to_process)
    logger.info(f"[@progress] æ£€æµ‹å‹ç¼©åŒ…å®Œæ•´æ€§ (0/{total_files}) 0%")

    # å®šä¹‰å•ä¸ªæ–‡ä»¶å¤„ç†å‡½æ•°
    def process_single_file(file_path, file_index):
        logger.info(f"[#status] ğŸ” æ­£åœ¨æ£€æµ‹: {file_path}")
        is_valid = check_archive(file_path)
        result = {
            'path': file_path,
            'valid': is_valid,
            'time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        # æ›´æ–°è¿›åº¦
        progress_percentage = int((file_index + 1) / total_files * 100)
        logger.info(f"[@progress] æ£€æµ‹å‹ç¼©åŒ…å®Œæ•´æ€§ ({file_index + 1}/{total_files}) {progress_percentage}%")
        return result

    # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†æ–‡ä»¶
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # ä½¿ç”¨enumerateè·å–ç´¢å¼•ï¼Œæ–¹ä¾¿æ›´æ–°è¿›åº¦
        futures = [executor.submit(process_single_file, file_path, i) for i, file_path in enumerate(files_to_process)]
        
        # å¤„ç†ç»“æœ
        for future in concurrent.futures.as_completed(futures):
            result = future.result()
            file_path = result['path']
            is_valid = result['valid']
            
            check_history[file_path] = {
                'time': result['time'],
                'valid': is_valid
            }
            
            if not is_valid:
                new_path = file_path + '.tdel'
                # å¦‚æœ.tdelæ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤å®ƒ
                if os.path.exists(new_path):
                    try:
                        os.remove(new_path)
                        logger.info(f"[#status] ğŸ—‘ï¸ åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶: {new_path}")
                    except Exception as e:
                        logger.error(f"[#error] åˆ é™¤æ–‡ä»¶ {new_path} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                        continue
                
                try:
                    os.rename(file_path, new_path)
                    logger.warning(f"[#warning] âš ï¸ æ–‡ä»¶æŸå,å·²é‡å‘½åä¸º: {new_path}")
                except Exception as e:
                    logger.error(f"[#error] é‡å‘½åæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            else:
                logger.info(f"[#success] âœ… æ–‡ä»¶å®Œå¥½: {file_path}")
            
            # å®šæœŸä¿å­˜æ£€æŸ¥å†å²
            save_check_history(check_history)

    # å¤„ç†ç»“æœçš„å¾ªç¯ç»“æŸåï¼Œæ·»åŠ åˆ é™¤ç©ºæ–‡ä»¶å¤¹çš„åŠŸèƒ½
    removed_count = 0
    logger.info(f"[@progress] æ¸…ç†ç©ºæ–‡ä»¶å¤¹ (0/100) 0%")
    
    # è·å–ç›®å½•æ€»æ•°ä»¥è®¡ç®—è¿›åº¦
    dir_count = sum(len(dirs) for _, dirs, _ in os.walk(directory))
    processed_dirs = 0
    
    for root, dirs, _ in os.walk(directory, topdown=False):
        for dir_name in dirs:
            dir_path = os.path.join(root, dir_name)
            try:
                if not os.listdir(dir_path):  # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦ä¸ºç©º
                    os.rmdir(dir_path)
                    removed_count += 1
                    logger.info(f"[#status] ğŸ—‘ï¸ å·²åˆ é™¤ç©ºæ–‡ä»¶å¤¹: {dir_path}")
            except Exception as e:
                logger.error(f"[#error] åˆ é™¤ç©ºæ–‡ä»¶å¤¹å¤±è´¥ {dir_path}: {str(e)}")
            
            # æ›´æ–°è¿›åº¦
            processed_dirs += 1
            progress = int(processed_dirs / dir_count * 100) if dir_count > 0 else 100
            logger.info(f"[@progress] æ¸…ç†ç©ºæ–‡ä»¶å¤¹ ({processed_dirs}/{dir_count}) {progress}%")
    
    logger.info(f"[@progress] æ¸…ç†ç©ºæ–‡ä»¶å¤¹ ({dir_count}/{dir_count}) 100%")
    if removed_count > 0:
        logger.info(f"[#success] âœ¨ å…±åˆ é™¤äº† {removed_count} ä¸ªç©ºæ–‡ä»¶å¤¹")

def main():
    parser = argparse.ArgumentParser(description='å‹ç¼©åŒ…å®Œæ•´æ€§æ£€æŸ¥å·¥å…·')
    parser.add_argument('paths', nargs='*', help='è¦å¤„ç†çš„è·¯å¾„åˆ—è¡¨')
    parser.add_argument('-c', '--clipboard', action='store_true', help='ä»å‰ªè´´æ¿è¯»å–è·¯å¾„')
    args = parser.parse_args()

    # åˆå§‹åŒ–TextualLogger
    TextualLoggerManager.set_layout(TEXTUAL_LAYOUT, config_info['log_file'])
    
    # è·å–è¦å¤„ç†çš„è·¯å¾„
    directories = []
    
    if args.clipboard:
        directories.extend(get_paths_from_clipboard())
    elif args.paths:
        for path_str in args.paths:
            path = Path(path_str.strip('"').strip("'"))
            if path.exists():
                directories.append(path)
            else:
                logger.warning(f"[#warning] âš ï¸ è­¦å‘Šï¼šè·¯å¾„ä¸å­˜åœ¨ - {path_str}")
    else:
        default_path = Path(r"D:\3EHV")
        if default_path.exists():
            directories.append(default_path)
            logger.info(f"[#status] ğŸ“‚ ä½¿ç”¨é»˜è®¤è·¯å¾„: {default_path}")
        else:
            logger.error("[#error] âŒ é»˜è®¤è·¯å¾„ä¸å­˜åœ¨")
            return

    if not directories:
        logger.error("[#error] âŒ æœªæä¾›ä»»ä½•æœ‰æ•ˆçš„è·¯å¾„")
        return

    skip_checked = True
    # å¯ä»¥æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´çº¿ç¨‹æ•°
    max_workers = os.cpu_count() or 4
    
    # å¤„ç†æ¯ä¸ªç›®å½•
    total_dirs = len(directories)
    for idx, directory in enumerate(directories):
        dir_progress = int((idx / total_dirs) * 100) if total_dirs > 0 else 100
        logger.info(f"[@progress] å¤„ç†ç›®å½• ({idx+1}/{total_dirs}) {dir_progress}%")
        logger.info(f"[#status] ğŸ“‚ å¼€å§‹å¤„ç†ç›®å½•: {directory}")
        process_directory(directory, skip_checked, max_workers=max_workers)
        logger.info(f"[#success] âœ… ç›®å½•å¤„ç†å®Œæˆ: {directory}")
    
    # æœ€ç»ˆå®Œæˆ
    logger.info(f"[@progress] å¤„ç†ç›®å½• ({total_dirs}/{total_dirs}) 100%")
    
if __name__ == "__main__":
    main()