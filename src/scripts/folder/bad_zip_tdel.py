import os
import subprocess
import yaml
from datetime import datetime
import concurrent.futures
from functools import partial
import shutil
import argparse
import pyperclip
from pathlib import Path
import sys
import logging
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from nodes.tui.textual_logger import TextualLoggerManager
from nodes.record.logger_config import setup_logger

# è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
HISTORY_FILE = os.path.join(SCRIPT_DIR, 'archive_check_history.yaml')

# é…ç½®æ—¥å¿—é¢æ¿å¸ƒå±€
TEXTUAL_LAYOUT = {
    "status": {
        "ratio": 2,
        "title": "ğŸ“Š çŠ¶æ€ä¿¡æ¯",
        "style": "lightblue"
    },
    "progress": {
        "ratio": 2,
        "title": "ğŸ”„ å¤„ç†è¿›åº¦",
        "style": "lightcyan"
    },
    "success": {
        "ratio": 3,
        "title": "âœ… æˆåŠŸä¿¡æ¯",
        "style": "lightgreen"
    },
    "warning": {
        "ratio": 2,
        "title": "âš ï¸ è­¦å‘Šä¿¡æ¯",
        "style": "lightyellow"
    },
    "error": {
        "ratio": 2,
        "title": "âŒ é”™è¯¯ä¿¡æ¯",
        "style": "lightred"
    }
}

# åˆå§‹åŒ–æ—¥å¿—
config = {
    'script_name': 'bad_zip_tdel',
    'console_enabled': False
}
logger, config_info = setup_logger(config)

def load_check_history():
    """åŠ è½½æ£€æµ‹å†å²è®°å½•"""
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f) or {}
    return {}

def save_check_history(history):
    """ä¿å­˜æ£€æµ‹å†å²è®°å½•"""
    with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
        yaml.dump(history, f, allow_unicode=True, sort_keys=False)

def check_archive(file_path):
    """æ£€æµ‹å‹ç¼©åŒ…æ˜¯å¦æŸå"""
    try:
        result = subprocess.run(['7z', 't', file_path], 
                              capture_output=True, 
                              text=True)
        return result.returncode == 0
    except Exception as e:
        logger.error(f"âŒ æ£€æµ‹æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return False

def get_archive_files(directory, archive_extensions):
    """å¿«é€Ÿæ”¶é›†éœ€è¦å¤„ç†çš„æ–‡ä»¶"""
    for root, _, files in os.walk(directory):
        for filename in files:
            if any(filename.lower().endswith(ext) for ext in archive_extensions):
                yield os.path.join(root, filename)

def get_paths_from_clipboard():
    """ä»å‰ªè´´æ¿è¯»å–å¤šè¡Œè·¯å¾„"""
    try:
        clipboard_content = pyperclip.paste()
        if not clipboard_content:
            return []
            
        paths = [
            Path(path.strip().strip('"').strip("'"))
            for path in clipboard_content.splitlines() 
            if path.strip()
        ]
        
        valid_paths = [
            path for path in paths 
            if path.exists()
        ]
        
        if valid_paths:
            logger.info(f"ğŸ“‹ ä»å‰ªè´´æ¿è¯»å–åˆ° {len(valid_paths)} ä¸ªæœ‰æ•ˆè·¯å¾„")
        else:
            logger.warning("âš ï¸ å‰ªè´´æ¿ä¸­æ²¡æœ‰æœ‰æ•ˆè·¯å¾„")
            
        return valid_paths
        
    except Exception as e:
        logger.error(f"âŒ è¯»å–å‰ªè´´æ¿æ—¶å‡ºé”™: {e}")
        return []

def process_directory(directory, skip_checked=False, max_workers=4):
    """å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰å‹ç¼©åŒ…æ–‡ä»¶"""
    archive_extensions = ('.zip', '.rar', '.7z', '.cbz')
    check_history = load_check_history()
    
    # åˆ é™¤temp_å¼€å¤´çš„æ–‡ä»¶å¤¹
    for root, dirs, _ in os.walk(directory, topdown=True):
        for dir_name in dirs[:]:  # ä½¿ç”¨åˆ‡ç‰‡åˆ›å»ºå‰¯æœ¬ä»¥é¿å…åœ¨è¿­ä»£æ—¶ä¿®æ”¹åˆ—è¡¨
            if dir_name.startswith('temp_'):
                try:
                    dir_path = os.path.join(root, dir_name)
                    logger.info(f"[@status]ğŸ—‘ï¸ æ­£åœ¨åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤¹: {dir_path}")
                    shutil.rmtree(dir_path)
                except Exception as e:
                    logger.error(f"[@error]åˆ é™¤æ–‡ä»¶å¤¹ {dir_path} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

    # æ”¶é›†éœ€è¦å¤„ç†çš„æ–‡ä»¶
    files_to_process = []
    for root, _, files in os.walk(directory):
        for filename in files:
            if filename.lower().endswith(archive_extensions):
                file_path = os.path.join(root, filename)
                if file_path.endswith('.tdel'):
                    continue
                if skip_checked and file_path in check_history and check_history[file_path]['valid']:
                    logger.info(f"[@status]â­ï¸ è·³è¿‡å·²æ£€æŸ¥ä¸”å®Œå¥½çš„æ–‡ä»¶: {file_path}")
                    continue
                files_to_process.append(file_path)

    if not files_to_process:
        logger.info("[@status]âœ¨ æ²¡æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶")
        return

    # æ›´æ–°è¿›åº¦ä¿¡æ¯
    total_files = len(files_to_process)
    logger.info(f"[@progress]æ£€æµ‹å‹ç¼©åŒ…å®Œæ•´æ€§ (0/{total_files}) 0%")

    # å®šä¹‰å•ä¸ªæ–‡ä»¶å¤„ç†å‡½æ•°
    def process_single_file(file_path):
        logger.info(f"[@status]ğŸ” æ­£åœ¨æ£€æµ‹: {file_path}")
        is_valid = check_archive(file_path)
        result = {
            'path': file_path,
            'valid': is_valid,
            'time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        return result

    # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†æ–‡ä»¶
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = []
        for file_path in files_to_process:
            future = executor.submit(process_single_file, file_path)
            futures.append(future)
        
        # å¤„ç†ç»“æœ
        completed = 0
        for future in concurrent.futures.as_completed(futures):
            completed += 1
            progress_percentage = int(completed / total_files * 100)
            logger.info(f"[@progress]æ£€æµ‹å‹ç¼©åŒ…å®Œæ•´æ€§ ({completed}/{total_files}) {progress_percentage}%")
            
            result = future.result()
            file_path = result['path']
            is_valid = result['valid']
            
            check_history[file_path] = {
                'time': result['time'],
                'valid': is_valid
            }
            
            if not is_valid:
                new_path = file_path + '.tdel'
                # å¦‚æœ.tdelæ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤å®ƒ
                if os.path.exists(new_path):
                    try:
                        os.remove(new_path)
                        logger.info(f"[@status]ğŸ—‘ï¸ åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶: {new_path}")
                    except Exception as e:
                        logger.error(f"[@error]åˆ é™¤æ–‡ä»¶ {new_path} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                        continue
                
                try:
                    os.rename(file_path, new_path)
                    logger.warning(f"[@warning]âš ï¸ æ–‡ä»¶æŸå,å·²é‡å‘½åä¸º: {new_path}")
                except Exception as e:
                    logger.error(f"[@error]é‡å‘½åæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            else:
                logger.info(f"[@success]âœ… æ–‡ä»¶å®Œå¥½: {file_path}")
            
            # å®šæœŸä¿å­˜æ£€æŸ¥å†å²
            save_check_history(check_history)

    # å¤„ç†ç»“æœçš„å¾ªç¯ç»“æŸåï¼Œæ·»åŠ åˆ é™¤ç©ºæ–‡ä»¶å¤¹çš„åŠŸèƒ½
    removed_count = 0
    for root, dirs, _ in os.walk(directory, topdown=False):
        for dir_name in dirs:
            dir_path = os.path.join(root, dir_name)
            try:
                if not os.listdir(dir_path):  # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦ä¸ºç©º
                    os.rmdir(dir_path)
                    removed_count += 1
                    logger.info(f"[@status]ğŸ—‘ï¸ å·²åˆ é™¤ç©ºæ–‡ä»¶å¤¹: {dir_path}")
            except Exception as e:
                logger.error(f"[@error]åˆ é™¤ç©ºæ–‡ä»¶å¤¹å¤±è´¥ {dir_path}: {str(e)}")
    
    if removed_count > 0:
        logger.info(f"[@success]âœ¨ å…±åˆ é™¤äº† {removed_count} ä¸ªç©ºæ–‡ä»¶å¤¹")

def main():
    parser = argparse.ArgumentParser(description='å‹ç¼©åŒ…å®Œæ•´æ€§æ£€æŸ¥å·¥å…·')
    parser.add_argument('paths', nargs='*', help='è¦å¤„ç†çš„è·¯å¾„åˆ—è¡¨')
    parser.add_argument('-c', '--clipboard', action='store_true', help='ä»å‰ªè´´æ¿è¯»å–è·¯å¾„')
    args = parser.parse_args()

    # åˆå§‹åŒ–TextualLogger
    TextualLoggerManager.set_layout(TEXTUAL_LAYOUT, config_info['log_file'])
    
    # è·å–è¦å¤„ç†çš„è·¯å¾„
    directories = []
    
    if args.clipboard:
        directories.extend(get_paths_from_clipboard())
    elif args.paths:
        for path_str in args.paths:
            path = Path(path_str.strip('"').strip("'"))
            if path.exists():
                directories.append(path)
            else:
                logger.warning(f"âš ï¸ è­¦å‘Šï¼šè·¯å¾„ä¸å­˜åœ¨ - {path_str}")
    else:
        default_path = Path(r"D:\3EHV")
        if default_path.exists():
            directories.append(default_path)
            logger.info(f"ğŸ“‚ ä½¿ç”¨é»˜è®¤è·¯å¾„: {default_path}")
        else:
            logger.error("âŒ é»˜è®¤è·¯å¾„ä¸å­˜åœ¨")
            return

    if not directories:
        logger.error("âŒ æœªæä¾›ä»»ä½•æœ‰æ•ˆçš„è·¯å¾„")
        return

    skip_checked = True
    # å¯ä»¥æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´çº¿ç¨‹æ•°
    max_workers = os.cpu_count() or 4
    
    # å¤„ç†æ¯ä¸ªç›®å½•
    for directory in directories:
        logger.info(f"[@status]ğŸ“‚ å¼€å§‹å¤„ç†ç›®å½•: {directory}")
        process_directory(directory, skip_checked, max_workers=max_workers)
        logger.info(f"[@success]âœ… ç›®å½•å¤„ç†å®Œæˆ: {directory}")
    
if __name__ == "__main__":
    main()